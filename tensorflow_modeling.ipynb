{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNsplklf0jVe"
      },
      "source": [
        "## Initial installs and imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "yL9VYWbBSwe1"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install tensorflow_decision_forests;\n",
        "%pip install plotly\n",
        "%pip install dtreeviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Ei2E4POD08ab"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.io as pio\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import polars as pl\n",
        "import plotly.express as px\n",
        "import dtreeviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "OmAbpYbeIbUM"
      },
      "outputs": [],
      "source": [
        "train_csv = \"/content/train.csv\"\n",
        "test_csv = \"/content/test.csv\"\n",
        "pio.templates.default = \"simple_white\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "VuIIBEeuSD7e"
      },
      "outputs": [],
      "source": [
        "train = pl.read_csv(train_csv)\n",
        "test = pl.read_csv(test_csv)\n",
        "\n",
        "train = train.select(\n",
        "    pl.all().name.map(lambda col_name: col_name.lower())\n",
        ").with_row_index()\n",
        "\n",
        "test = test.select(\n",
        "    pl.all().name.map(lambda col_name: col_name.lower())\n",
        ").with_row_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6ioV_rxSD7n"
      },
      "source": [
        "# Tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYA0RmQj4tS8"
      },
      "source": [
        "We'll use tensorflow's decision forests package to create a random forest of classifiers for this data. From there we'll convert our training and testing dataframes into keras datasets to fit the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "UQcJHmi-SD7n"
      },
      "outputs": [],
      "source": [
        "train_pd = train.to_pandas().iloc[:, :].drop(\"name\", axis=1)\n",
        "\n",
        "train_pd[\n",
        "    [\n",
        "        \"vip\",\n",
        "        \"cryosleep\",\n",
        "        \"foodcourt\",\n",
        "        \"shoppingmall\",\n",
        "        \"spa\",\n",
        "        \"vrdeck\",\n",
        "        \"roomservice\",\n",
        "        \"age\",\n",
        "    ]\n",
        "] = train_pd[\n",
        "    [\n",
        "        \"vip\",\n",
        "        \"cryosleep\",\n",
        "        \"foodcourt\",\n",
        "        \"shoppingmall\",\n",
        "        \"spa\",\n",
        "        \"vrdeck\",\n",
        "        \"roomservice\",\n",
        "        \"age\",\n",
        "    ]\n",
        "].fillna(value=0)\n",
        "\n",
        "train_pd[[\"transported\", \"vip\", \"cryosleep\"]] = train_pd[\n",
        "    [\"transported\", \"vip\", \"cryosleep\"]\n",
        "].astype(int)\n",
        "\n",
        "train_pd[[\"deck\", \"cabin_num\", \"side\"]] = train_pd[\"cabin\"].str.split(\"/\", expand=True)\n",
        "train_pd = train_pd.drop(\"cabin\", axis=1)\n",
        "\n",
        "train_pd[\"cabin_num\"] = train_pd[\"cabin_num\"].fillna(\"0\")\n",
        "for col in train_pd.select_dtypes(include=[\"object\"]).columns:\n",
        "    train_pd[col] = train_pd[col].fillna(\"\")\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    train_pd, train_pd[\"transported\"], test_size=0\n",
        ")\n",
        "\n",
        "# Convert dataframes to keras datasets\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(x_train, label=\"transported\")\n",
        "valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(x_val, label=\"transported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "-rbwBlKjClvR"
      },
      "outputs": [],
      "source": [
        "train_pd[\"cabin_num\"] = train_pd[\"cabin_num\"].fillna(\"0\")\n",
        "train_pd[\"age\"] = train_pd[\"age\"].fillna(np.median(train_pd.age))\n",
        "for col in train_pd.select_dtypes(include=[\"object\"]).columns:\n",
        "    train_pd[col] = train_pd[col].fillna(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHI-pIDK5C2q"
      },
      "source": [
        "Now that we've initialized our data, let's use automated hyperparameter tuning to fit our ensemble to the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjZuwwcFSD7n",
        "outputId": "c4b6aecc-9d20-48e0-f325-3fe82bdb2996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpch2zaac5 as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: {'homeplanet': <tf.Tensor 'data:0' shape=(None,) dtype=string>, 'cryosleep': <tf.Tensor 'data_1:0' shape=(None,) dtype=int64>, 'destination': <tf.Tensor 'data_2:0' shape=(None,) dtype=string>, 'age': <tf.Tensor 'data_3:0' shape=(None,) dtype=float64>, 'vip': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'roomservice': <tf.Tensor 'data_5:0' shape=(None,) dtype=float64>, 'foodcourt': <tf.Tensor 'data_6:0' shape=(None,) dtype=float64>, 'shoppingmall': <tf.Tensor 'data_7:0' shape=(None,) dtype=float64>, 'spa': <tf.Tensor 'data_8:0' shape=(None,) dtype=float64>, 'vrdeck': <tf.Tensor 'data_9:0' shape=(None,) dtype=float64>, 'deck': <tf.Tensor 'data_10:0' shape=(None,) dtype=string>, 'cabin_num': <tf.Tensor 'data_11:0' shape=(None,) dtype=string>, 'side': <tf.Tensor 'data_12:0' shape=(None,) dtype=string>}\n",
            "Label: Tensor(\"data_13:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'homeplanet': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data:0' shape=(None,) dtype=string>), 'cryosleep': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'destination': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_2:0' shape=(None,) dtype=string>), 'age': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'vip': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'roomservice': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'foodcourt': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'shoppingmall': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>), 'spa': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_6:0' shape=(None,) dtype=float32>), 'vrdeck': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_7:0' shape=(None,) dtype=float32>), 'deck': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_10:0' shape=(None,) dtype=string>), 'cabin_num': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_11:0' shape=(None,) dtype=string>), 'side': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_12:0' shape=(None,) dtype=string>)}\n",
            "Training dataset read in 0:00:00.320775. Found 6954 examples.\n",
            "Training model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1727922209.465732     401 kernel.cc:774] Start Yggdrasil model training\n",
            "I0000 00:00:1727922209.465779     401 kernel.cc:775] Collect training examples\n",
            "I0000 00:00:1727922209.465800     401 kernel.cc:787] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: CATEGORICAL\n",
            "  categorial {\n",
            "    min_vocab_frequency: 0\n",
            "    max_vocab_count: -1\n",
            "  }\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "I0000 00:00:1727922209.465940     401 kernel.cc:394] Number of batches: 7\n",
            "I0000 00:00:1727922209.465953     401 kernel.cc:395] Number of examples: 6954\n",
            "I0000 00:00:1727922209.470392     401 data_spec_inference.cc:306] 1277 item(s) have been pruned (i.e. they are considered out of dictionary) for the column cabin_num (475 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "I0000 00:00:1727922209.470673     401 data_spec_inference.cc:306] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column deck (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "I0000 00:00:1727922209.473111     401 kernel.cc:794] Training dataset:\n",
            "Number of records: 6954\n",
            "Number of columns: 14\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 8 (57.1429%)\n",
            "\tCATEGORICAL: 6 (42.8571%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 8 (57.1429%)\n",
            "\t1: \"age\" NUMERICAL mean:28.1429 min:0 max:79 sd:14.8607\n",
            "\t3: \"cryosleep\" NUMERICAL mean:0.346707 min:0 max:1 sd:0.475921\n",
            "\t6: \"foodcourt\" NUMERICAL mean:452.173 min:0 max:29813 sd:1628.11\n",
            "\t8: \"roomservice\" NUMERICAL mean:217.382 min:0 max:8586 sd:628.9\n",
            "\t9: \"shoppingmall\" NUMERICAL mean:166.527 min:0 max:12253 sd:530.396\n",
            "\t11: \"spa\" NUMERICAL mean:304.435 min:0 max:22408 sd:1142.74\n",
            "\t12: \"vip\" NUMERICAL mean:0.0209951 min:0 max:1 sd:0.143368\n",
            "\t13: \"vrdeck\" NUMERICAL mean:302.299 min:0 max:24133 sd:1169.54\n",
            "\n",
            "CATEGORICAL: 6 (42.8571%)\n",
            "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
            "\t2: \"cabin_num\" CATEGORICAL has-dict vocab-size:476 num-oods:2858 (41.0986%) most-frequent:\"<OOD>\" 2858 (41.0986%)\n",
            "\t4: \"deck\" CATEGORICAL num-nas:156 (2.24331%) has-dict vocab-size:8 num-oods:4 (0.0588408%) most-frequent:\"F\" 2240 (32.9509%)\n",
            "\t5: \"destination\" CATEGORICAL num-nas:148 (2.12827%) has-dict vocab-size:4 zero-ood-items most-frequent:\"TRAPPIST-1e\" 4709 (69.189%)\n",
            "\t7: \"homeplanet\" CATEGORICAL num-nas:159 (2.28645%) has-dict vocab-size:4 zero-ood-items most-frequent:\"Earth\" 3665 (53.9367%)\n",
            "\t10: \"side\" CATEGORICAL num-nas:156 (2.24331%) has-dict vocab-size:3 zero-ood-items most-frequent:\"S\" 3410 (50.1618%)\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "I0000 00:00:1727922209.473295     401 kernel.cc:810] Configure learner\n",
            "I0000 00:00:1727922209.473625     401 kernel.cc:824] Training config:\n",
            "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
            "features: \"^age$\"\n",
            "features: \"^cabin_num$\"\n",
            "features: \"^cryosleep$\"\n",
            "features: \"^deck$\"\n",
            "features: \"^destination$\"\n",
            "features: \"^foodcourt$\"\n",
            "features: \"^homeplanet$\"\n",
            "features: \"^roomservice$\"\n",
            "features: \"^shoppingmall$\"\n",
            "features: \"^side$\"\n",
            "features: \"^spa$\"\n",
            "features: \"^vip$\"\n",
            "features: \"^vrdeck$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: CLASSIFICATION\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
            "  base_learner {\n",
            "    learner: \"RANDOM_FOREST\"\n",
            "    features: \"^age$\"\n",
            "    features: \"^cabin_num$\"\n",
            "    features: \"^cryosleep$\"\n",
            "    features: \"^deck$\"\n",
            "    features: \"^destination$\"\n",
            "    features: \"^foodcourt$\"\n",
            "    features: \"^homeplanet$\"\n",
            "    features: \"^roomservice$\"\n",
            "    features: \"^shoppingmall$\"\n",
            "    features: \"^side$\"\n",
            "    features: \"^spa$\"\n",
            "    features: \"^vip$\"\n",
            "    features: \"^vrdeck$\"\n",
            "    label: \"^__LABEL$\"\n",
            "    task: CLASSIFICATION\n",
            "    random_seed: 123456\n",
            "    pure_serving_model: false\n",
            "    [yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "      num_trees: 300\n",
            "      decision_tree {\n",
            "        max_depth: 16\n",
            "        min_examples: 5\n",
            "        in_split_min_examples_check: true\n",
            "        keep_non_leaf_label_distribution: true\n",
            "        num_candidate_attributes: 0\n",
            "        missing_value_policy: GLOBAL_IMPUTATION\n",
            "        allow_na_conditions: false\n",
            "        categorical_set_greedy_forward {\n",
            "          sampling: 0.1\n",
            "          max_num_items: -1\n",
            "          min_item_frequency: 1\n",
            "        }\n",
            "        growing_strategy_local {\n",
            "        }\n",
            "        categorical {\n",
            "          cart {\n",
            "          }\n",
            "        }\n",
            "        axis_aligned_split {\n",
            "        }\n",
            "        internal {\n",
            "          sorting_strategy: PRESORTED\n",
            "        }\n",
            "        uplift {\n",
            "          min_examples_in_treatment: 5\n",
            "          split_score: KULLBACK_LEIBLER\n",
            "        }\n",
            "      }\n",
            "      winner_take_all_inference: true\n",
            "      compute_oob_performances: true\n",
            "      compute_oob_variable_importances: false\n",
            "      num_oob_variable_importances_permutations: 1\n",
            "      bootstrap_training_dataset: true\n",
            "      bootstrap_size_ratio: 1\n",
            "      adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "      sampling_with_replacement: true\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    optimizer_key: \"RANDOM\"\n",
            "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
            "      num_trials: 20\n",
            "    }\n",
            "  }\n",
            "  base_learner_deployment {\n",
            "    num_threads: 1\n",
            "  }\n",
            "  predefined_search_space {\n",
            "  }\n",
            "}\n",
            "\n",
            "I0000 00:00:1727922209.473777     401 kernel.cc:827] Deployment config:\n",
            "cache_path: \"/tmp/tmpch2zaac5/working_cache\"\n",
            "num_threads: 2\n",
            "try_resume_training: true\n",
            "\n",
            "I0000 00:00:1727922209.473950   20296 kernel.cc:888] Train model\n",
            "2024-10-03 02:23:29.474313: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:209] Hyperparameter search space:\n",
            "fields {\n",
            "  name: \"split_axis\"\n",
            "  discrete_candidates {\n",
            "    possible_values {\n",
            "      categorical: \"AXIS_ALIGNED\"\n",
            "    }\n",
            "    possible_values {\n",
            "      categorical: \"SPARSE_OBLIQUE\"\n",
            "    }\n",
            "  }\n",
            "  children {\n",
            "    name: \"sparse_oblique_projection_density_factor\"\n",
            "    discrete_candidates {\n",
            "      possible_values {\n",
            "        real: 1\n",
            "      }\n",
            "      possible_values {\n",
            "        real: 2\n",
            "      }\n",
            "      possible_values {\n",
            "        real: 3\n",
            "      }\n",
            "      possible_values {\n",
            "        real: 4\n",
            "      }\n",
            "      possible_values {\n",
            "        real: 5\n",
            "      }\n",
            "    }\n",
            "    parent_discrete_values {\n",
            "      possible_values {\n",
            "        categorical: \"SPARSE_OBLIQUE\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  children {\n",
            "    name: \"sparse_oblique_normalization\"\n",
            "    discrete_candidates {\n",
            "      possible_values {\n",
            "        categorical: \"NONE\"\n",
            "      }\n",
            "      possible_values {\n",
            "        categorical: \"STANDARD_DEVIATION\"\n",
            "      }\n",
            "      possible_values {\n",
            "        categorical: \"MIN_MAX\"\n",
            "      }\n",
            "    }\n",
            "    parent_discrete_values {\n",
            "      possible_values {\n",
            "        categorical: \"SPARSE_OBLIQUE\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  children {\n",
            "    name: \"sparse_oblique_weights\"\n",
            "    discrete_candidates {\n",
            "      possible_values {\n",
            "        categorical: \"BINARY\"\n",
            "      }\n",
            "      possible_values {\n",
            "        categorical: \"CONTINUOUS\"\n",
            "      }\n",
            "    }\n",
            "    parent_discrete_values {\n",
            "      possible_values {\n",
            "        categorical: \"SPARSE_OBLIQUE\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"categorical_algorithm\"\n",
            "  discrete_candidates {\n",
            "    possible_values {\n",
            "      categorical: \"CART\"\n",
            "    }\n",
            "    possible_values {\n",
            "      categorical: \"RANDOM\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"winner_take_all\"\n",
            "  discrete_candidates {\n",
            "    possible_values {\n",
            "      categorical: \"true\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"max_depth\"\n",
            "  discrete_candidates {\n",
            "    possible_values {\n",
            "      integer: 12\n",
            "    }\n",
            "    possible_values {\n",
            "      integer: 16\n",
            "    }\n",
            "    possible_values {\n",
            "      integer: 20\n",
            "    }\n",
            "    possible_values {\n",
            "      integer: 25\n",
            "    }\n",
            "    possible_values {\n",
            "      integer: 30\n",
            "    }\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"min_examples\"\n",
            "  discrete_candidates {\n",
            "    possible_values {\n",
            "      integer: 1\n",
            "    }\n",
            "    possible_values {\n",
            "      integer: 2\n",
            "    }\n",
            "    possible_values {\n",
            "      integer: 5\n",
            "    }\n",
            "    possible_values {\n",
            "      integer: 10\n",
            "    }\n",
            "    possible_values {\n",
            "      integer: 40\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "2024-10-03 02:23:29.474400: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:493] Start local tuner with 1 parallel trial(s), each with 2 thread(s)\n",
            "I0000 00:00:1727922209.475908   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727922210.463414   20298 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.761905 logloss:8.58182\n",
            "I0000 00:00:1727922220.468736   20298 random_forest.cc:812] Training of tree  10/300 (tree index:9) done accuracy:0.780201 logloss:4.11099\n",
            "I0000 00:00:1727922230.212367   20298 random_forest.cc:812] Training of tree  20/300 (tree index:19) done accuracy:0.788467 logloss:2.36761\n",
            "I0000 00:00:1727922240.260690   20298 random_forest.cc:812] Training of tree  29/300 (tree index:28) done accuracy:0.788898 logloss:1.88697\n",
            "I0000 00:00:1727922246.529185   20298 random_forest.cc:812] Training of tree  39/300 (tree index:38) done accuracy:0.792206 logloss:1.69878\n",
            "I0000 00:00:1727922252.920780   20298 random_forest.cc:812] Training of tree  49/300 (tree index:48) done accuracy:0.790049 logloss:1.51948\n",
            "I0000 00:00:1727922260.452261   20298 random_forest.cc:812] Training of tree  59/300 (tree index:58) done accuracy:0.792206 logloss:1.39214\n",
            "I0000 00:00:1727922266.741970   20298 random_forest.cc:812] Training of tree  69/300 (tree index:68) done accuracy:0.792494 logloss:1.27041\n",
            "I0000 00:00:1727922274.711063   20298 random_forest.cc:812] Training of tree  79/300 (tree index:78) done accuracy:0.794075 logloss:1.22124\n",
            "I0000 00:00:1727922280.889137   20298 random_forest.cc:812] Training of tree  89/300 (tree index:88) done accuracy:0.791631 logloss:1.15997\n",
            "I0000 00:00:1727922289.111676   20298 random_forest.cc:812] Training of tree  99/300 (tree index:98) done accuracy:0.793356 logloss:1.12441\n",
            "I0000 00:00:1727922296.019808   20298 random_forest.cc:812] Training of tree  109/300 (tree index:108) done accuracy:0.794363 logloss:1.11008\n",
            "I0000 00:00:1727922303.347180   20298 random_forest.cc:812] Training of tree  119/300 (tree index:118) done accuracy:0.7935 logloss:1.07215\n",
            "I0000 00:00:1727922309.731343   20298 random_forest.cc:812] Training of tree  129/300 (tree index:128) done accuracy:0.792494 logloss:1.04485\n",
            "I0000 00:00:1727922315.927674   20298 random_forest.cc:812] Training of tree  139/300 (tree index:138) done accuracy:0.791918 logloss:1.00294\n",
            "I0000 00:00:1727922321.074802   20298 random_forest.cc:812] Training of tree  149/300 (tree index:148) done accuracy:0.792781 logloss:0.975406\n",
            "I0000 00:00:1727922327.118146   20298 random_forest.cc:812] Training of tree  159/300 (tree index:158) done accuracy:0.793932 logloss:0.952561\n",
            "I0000 00:00:1727922332.358492   20298 random_forest.cc:812] Training of tree  169/300 (tree index:168) done accuracy:0.793213 logloss:0.946997\n",
            "I0000 00:00:1727922341.182211   20298 random_forest.cc:812] Training of tree  179/300 (tree index:178) done accuracy:0.792494 logloss:0.937736\n",
            "I0000 00:00:1727922348.432675   20298 random_forest.cc:812] Training of tree  189/300 (tree index:188) done accuracy:0.791056 logloss:0.928362\n",
            "I0000 00:00:1727922357.227582   20298 random_forest.cc:812] Training of tree  199/300 (tree index:198) done accuracy:0.792637 logloss:0.914683\n",
            "I0000 00:00:1727922364.605647   20298 random_forest.cc:812] Training of tree  209/300 (tree index:208) done accuracy:0.79235 logloss:0.905731\n",
            "I0000 00:00:1727922370.701716   20298 random_forest.cc:812] Training of tree  219/300 (tree index:218) done accuracy:0.792637 logloss:0.878659\n",
            "I0000 00:00:1727922376.154210   20298 random_forest.cc:812] Training of tree  229/300 (tree index:228) done accuracy:0.7935 logloss:0.859739\n",
            "I0000 00:00:1727922385.005393   20298 random_forest.cc:812] Training of tree  239/300 (tree index:238) done accuracy:0.793932 logloss:0.855415\n",
            "I0000 00:00:1727922390.779174   20298 random_forest.cc:812] Training of tree  249/300 (tree index:248) done accuracy:0.793644 logloss:0.84627\n",
            "I0000 00:00:1727922396.638919   20298 random_forest.cc:812] Training of tree  259/300 (tree index:258) done accuracy:0.794075 logloss:0.837796\n",
            "I0000 00:00:1727922401.816356   20298 random_forest.cc:812] Training of tree  269/300 (tree index:268) done accuracy:0.793356 logloss:0.833235\n",
            "I0000 00:00:1727922407.883141   20298 random_forest.cc:812] Training of tree  279/300 (tree index:278) done accuracy:0.793788 logloss:0.832852\n",
            "I0000 00:00:1727922413.130394   20298 random_forest.cc:812] Training of tree  289/300 (tree index:288) done accuracy:0.795082 logloss:0.818761\n",
            "I0000 00:00:1727922422.485090   20298 random_forest.cc:812] Training of tree  299/300 (tree index:298) done accuracy:0.795226 logloss:0.809854\n",
            "I0000 00:00:1727922423.305064   20298 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.79537 logloss:0.809825\n",
            "I0000 00:00:1727922423.307540   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.79537 logloss:0.809825\n",
            "2024-10-03 02:27:03.338032: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [1/20] Score: 0.79537 / 0.79537 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
            "I0000 00:00:1727922423.340635   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727922424.487009   21210 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.716221 logloss:10.2284\n",
            "I0000 00:00:1727922434.647003   21210 random_forest.cc:812] Training of tree  8/300 (tree index:7) done accuracy:0.748335 logloss:4.41512\n",
            "I0000 00:00:1727922444.388820   21210 random_forest.cc:812] Training of tree  18/300 (tree index:17) done accuracy:0.767515 logloss:1.88668\n",
            "I0000 00:00:1727922454.269239   21210 random_forest.cc:812] Training of tree  28/300 (tree index:27) done accuracy:0.776388 logloss:1.25327\n",
            "I0000 00:00:1727922463.724890   21210 random_forest.cc:812] Training of tree  38/300 (tree index:37) done accuracy:0.780127 logloss:1.0535\n",
            "I0000 00:00:1727922471.493085   21210 random_forest.cc:812] Training of tree  48/300 (tree index:47) done accuracy:0.781996 logloss:0.895829\n",
            "I0000 00:00:1727922481.409378   21210 random_forest.cc:812] Training of tree  58/300 (tree index:57) done accuracy:0.783865 logloss:0.771555\n",
            "I0000 00:00:1727922490.321819   21210 random_forest.cc:812] Training of tree  68/300 (tree index:67) done accuracy:0.784009 logloss:0.720519\n",
            "I0000 00:00:1727922497.879800   21210 random_forest.cc:812] Training of tree  78/300 (tree index:77) done accuracy:0.784441 logloss:0.686557\n",
            "I0000 00:00:1727922508.809676   21210 random_forest.cc:812] Training of tree  88/300 (tree index:87) done accuracy:0.784584 logloss:0.662738\n",
            "I0000 00:00:1727922518.125283   21210 random_forest.cc:812] Training of tree  98/300 (tree index:97) done accuracy:0.784728 logloss:0.652973\n",
            "I0000 00:00:1727922524.841534   21210 random_forest.cc:812] Training of tree  108/300 (tree index:107) done accuracy:0.78516 logloss:0.627331\n",
            "I0000 00:00:1727922532.208716   21210 random_forest.cc:812] Training of tree  118/300 (tree index:117) done accuracy:0.787604 logloss:0.612559\n",
            "I0000 00:00:1727922538.674641   21210 random_forest.cc:812] Training of tree  128/300 (tree index:127) done accuracy:0.787029 logloss:0.603406\n",
            "I0000 00:00:1727922546.262089   21210 random_forest.cc:812] Training of tree  138/300 (tree index:137) done accuracy:0.788323 logloss:0.598391\n",
            "I0000 00:00:1727922552.640591   21210 random_forest.cc:812] Training of tree  148/300 (tree index:147) done accuracy:0.788323 logloss:0.58421\n",
            "I0000 00:00:1727922560.330427   21210 random_forest.cc:812] Training of tree  158/300 (tree index:157) done accuracy:0.788898 logloss:0.584266\n",
            "I0000 00:00:1727922566.944641   21210 random_forest.cc:812] Training of tree  168/300 (tree index:167) done accuracy:0.789186 logloss:0.584311\n",
            "I0000 00:00:1727922574.449292   21210 random_forest.cc:812] Training of tree  178/300 (tree index:177) done accuracy:0.787317 logloss:0.584151\n",
            "I0000 00:00:1727922581.414146   21210 random_forest.cc:812] Training of tree  188/300 (tree index:187) done accuracy:0.787317 logloss:0.575033\n",
            "I0000 00:00:1727922588.613681   21210 random_forest.cc:812] Training of tree  198/300 (tree index:197) done accuracy:0.787604 logloss:0.570471\n",
            "I0000 00:00:1727922596.180016   21210 random_forest.cc:812] Training of tree  208/300 (tree index:207) done accuracy:0.786454 logloss:0.570622\n",
            "I0000 00:00:1727922602.794138   21210 random_forest.cc:812] Training of tree  218/300 (tree index:217) done accuracy:0.786741 logloss:0.570828\n",
            "I0000 00:00:1727922610.111701   21210 random_forest.cc:812] Training of tree  228/300 (tree index:227) done accuracy:0.787748 logloss:0.56568\n",
            "I0000 00:00:1727922616.824841   21210 random_forest.cc:812] Training of tree  238/300 (tree index:237) done accuracy:0.788179 logloss:0.565631\n",
            "I0000 00:00:1727922624.207878   21210 random_forest.cc:812] Training of tree  248/300 (tree index:247) done accuracy:0.788611 logloss:0.5652\n",
            "I0000 00:00:1727922631.516354   21210 random_forest.cc:812] Training of tree  258/300 (tree index:257) done accuracy:0.789186 logloss:0.560073\n",
            "I0000 00:00:1727922641.680133   21210 random_forest.cc:812] Training of tree  267/300 (tree index:266) done accuracy:0.789905 logloss:0.559893\n",
            "I0000 00:00:1727922650.242081   21210 random_forest.cc:812] Training of tree  277/300 (tree index:276) done accuracy:0.79048 logloss:0.559495\n",
            "I0000 00:00:1727922657.281053   21210 random_forest.cc:812] Training of tree  287/300 (tree index:286) done accuracy:0.789042 logloss:0.554708\n",
            "I0000 00:00:1727922665.717206   21210 random_forest.cc:812] Training of tree  297/300 (tree index:296) done accuracy:0.788036 logloss:0.550159\n",
            "I0000 00:00:1727922667.751385   21210 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.788467 logloss:0.550269\n",
            "I0000 00:00:1727922667.751579   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.788467 logloss:0.550269\n",
            "2024-10-03 02:31:07.864600: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [2/20] Score: 0.788467 / 0.79537 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
            "I0000 00:00:1727922667.864930   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727922668.662153   22233 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.737514 logloss:9.46094\n",
            "I0000 00:00:1727922676.224071   22233 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.76794 logloss:3.1891\n",
            "I0000 00:00:1727922683.541042   22233 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.777251 logloss:1.68784\n",
            "I0000 00:00:1727922691.983350   22233 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.784009 logloss:1.23624\n",
            "I0000 00:00:1727922699.827411   22233 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.786454 logloss:1.05102\n",
            "I0000 00:00:1727922707.115899   22233 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.788898 logloss:0.953048\n",
            "I0000 00:00:1727922716.323780   22233 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.788755 logloss:0.87661\n",
            "I0000 00:00:1727922723.258555   22233 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.79235 logloss:0.810696\n",
            "I0000 00:00:1727922731.479972   22233 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.791056 logloss:0.762148\n",
            "I0000 00:00:1727922738.760092   22233 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.791199 logloss:0.727289\n",
            "I0000 00:00:1727922747.554805   22233 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.790336 logloss:0.690295\n",
            "I0000 00:00:1727922754.822670   22233 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.792494 logloss:0.666024\n",
            "I0000 00:00:1727922763.161544   22233 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.791631 logloss:0.624735\n",
            "I0000 00:00:1727922770.709546   22233 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.789617 logloss:0.611364\n",
            "I0000 00:00:1727922778.560021   22233 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.791487 logloss:0.591879\n",
            "I0000 00:00:1727922786.991379   22233 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.791631 logloss:0.58599\n",
            "I0000 00:00:1727922793.690638   22233 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.791918 logloss:0.58095\n",
            "I0000 00:00:1727922803.219173   22233 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.793069 logloss:0.576164\n",
            "I0000 00:00:1727922809.032698   22233 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.7935 logloss:0.57138\n",
            "I0000 00:00:1727922817.537050   22233 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.792062 logloss:0.562212\n",
            "I0000 00:00:1727922824.068552   22233 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.792494 logloss:0.561974\n",
            "I0000 00:00:1727922831.672136   22233 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.792206 logloss:0.561232\n",
            "I0000 00:00:1727922839.418845   22233 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.794075 logloss:0.556444\n",
            "I0000 00:00:1727922847.014647   22233 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.793356 logloss:0.555783\n",
            "I0000 00:00:1727922855.237555   22233 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.794507 logloss:0.555458\n",
            "I0000 00:00:1727922861.933929   22233 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.7935 logloss:0.54603\n",
            "I0000 00:00:1727922870.768360   22233 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.7935 logloss:0.541355\n",
            "I0000 00:00:1727922878.543062   22233 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.7935 logloss:0.536727\n",
            "I0000 00:00:1727922885.761967   22233 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.793644 logloss:0.536461\n",
            "I0000 00:00:1727922893.647865   22233 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.793644 logloss:0.536302\n",
            "I0000 00:00:1727922899.131402   22233 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.794075 logloss:0.536365\n",
            "I0000 00:00:1727922899.131695   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.794075 logloss:0.536365\n",
            "2024-10-03 02:34:59.202530: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [3/20] Score: 0.794075 / 0.79537 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
            "I0000 00:00:1727922899.202884   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727922899.942705   23210 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.723577 logloss:9.96329\n",
            "I0000 00:00:1727922910.077712   23210 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.757957 logloss:3.33267\n",
            "I0000 00:00:1727922916.857615   23210 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.77495 logloss:1.70811\n",
            "I0000 00:00:1727922924.206032   23210 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.777826 logloss:1.20104\n",
            "I0000 00:00:1727922931.214425   23210 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.78214 logloss:1.01005\n",
            "I0000 00:00:1727922938.171854   23210 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.78631 logloss:0.883749\n",
            "I0000 00:00:1727922945.451759   23210 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.78631 logloss:0.79289\n",
            "I0000 00:00:1727922952.098815   23210 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.783865 logloss:0.706059\n",
            "I0000 00:00:1727922959.928495   23210 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.784153 logloss:0.673374\n",
            "I0000 00:00:1727922966.546549   23210 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.784441 logloss:0.65431\n",
            "I0000 00:00:1727922974.246778   23210 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.78214 logloss:0.624821\n",
            "I0000 00:00:1727922980.752304   23210 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.783722 logloss:0.601081\n",
            "I0000 00:00:1727922988.531936   23210 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.786166 logloss:0.58147\n",
            "I0000 00:00:1727922995.365397   23210 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.783865 logloss:0.580429\n",
            "I0000 00:00:1727923003.010897   23210 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.784872 logloss:0.575077\n",
            "I0000 00:00:1727923010.049986   23210 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.784584 logloss:0.569732\n",
            "I0000 00:00:1727923017.519030   23210 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.784584 logloss:0.56014\n",
            "I0000 00:00:1727923025.132933   23210 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.783865 logloss:0.555569\n",
            "I0000 00:00:1727923031.908988   23210 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.784872 logloss:0.555435\n",
            "I0000 00:00:1727923039.274945   23210 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.78516 logloss:0.546153\n",
            "I0000 00:00:1727923045.947461   23210 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.785879 logloss:0.545863\n",
            "I0000 00:00:1727923053.647511   23210 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.78631 logloss:0.545789\n",
            "I0000 00:00:1727923060.235281   23210 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.78631 logloss:0.540863\n",
            "I0000 00:00:1727923067.612698   23210 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.784872 logloss:0.54053\n",
            "I0000 00:00:1727923074.230861   23210 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.784009 logloss:0.526961\n",
            "I0000 00:00:1727923081.790755   23210 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.784872 logloss:0.527003\n",
            "I0000 00:00:1727923088.417721   23210 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.784872 logloss:0.52146\n",
            "I0000 00:00:1727923095.970584   23210 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.784728 logloss:0.516554\n",
            "I0000 00:00:1727923102.656392   23210 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.784584 logloss:0.516607\n",
            "I0000 00:00:1727923109.759928   23210 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.785447 logloss:0.516326\n",
            "I0000 00:00:1727923116.409139   23210 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.785879 logloss:0.511752\n",
            "I0000 00:00:1727923116.411839   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.785879 logloss:0.511752\n",
            "2024-10-03 02:38:36.620776: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [4/20] Score: 0.785879 / 0.79537 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
            "I0000 00:00:1727923116.628338   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727923117.529751   24106 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.754549 logloss:8.84695\n",
            "I0000 00:00:1727923122.544197   24106 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.767072 logloss:3.26165\n",
            "I0000 00:00:1727923127.688354   24106 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.778545 logloss:1.73907\n",
            "I0000 00:00:1727923133.521469   24106 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.78329 logloss:1.21586\n",
            "I0000 00:00:1727923138.506950   24106 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.782571 logloss:0.986694\n",
            "I0000 00:00:1727923144.496333   24106 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.784584 logloss:0.863984\n",
            "I0000 00:00:1727923149.564027   24106 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.78631 logloss:0.804076\n",
            "I0000 00:00:1727923154.680944   24106 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.787748 logloss:0.764206\n",
            "I0000 00:00:1727923160.005077   24106 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.788898 logloss:0.719599\n",
            "I0000 00:00:1727923164.756973   24106 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.789761 logloss:0.662695\n",
            "I0000 00:00:1727923170.649121   24106 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.791631 logloss:0.643716\n",
            "I0000 00:00:1727923175.719219   24106 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.789474 logloss:0.625171\n",
            "I0000 00:00:1727923180.880446   24106 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.791487 logloss:0.615675\n",
            "I0000 00:00:1727923186.692324   24106 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.79048 logloss:0.60631\n",
            "I0000 00:00:1727923191.576238   24106 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.791487 logloss:0.60648\n",
            "I0000 00:00:1727923197.225269   24106 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.792494 logloss:0.58312\n",
            "I0000 00:00:1727923202.322957   24106 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.793356 logloss:0.577427\n",
            "I0000 00:00:1727923207.365613   24106 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.793356 logloss:0.572919\n",
            "I0000 00:00:1727923212.780840   24106 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.793356 logloss:0.567553\n",
            "I0000 00:00:1727923217.686758   24106 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.793213 logloss:0.558074\n",
            "I0000 00:00:1727923223.523035   24106 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.791487 logloss:0.557878\n",
            "I0000 00:00:1727923228.535034   24106 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.792781 logloss:0.552964\n",
            "I0000 00:00:1727923233.389028   24106 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.792062 logloss:0.548339\n",
            "I0000 00:00:1727923239.030318   24106 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.793356 logloss:0.544019\n",
            "I0000 00:00:1727923243.714022   24106 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.792925 logloss:0.543595\n",
            "I0000 00:00:1727923249.877780   24106 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.792925 logloss:0.543153\n",
            "I0000 00:00:1727923254.569545   24106 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.792925 logloss:0.530195\n",
            "I0000 00:00:1727923259.041003   24106 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.792494 logloss:0.529844\n",
            "I0000 00:00:1727923264.802911   24106 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.793356 logloss:0.529519\n",
            "I0000 00:00:1727923269.524835   24106 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.7935 logloss:0.529425\n",
            "I0000 00:00:1727923274.114667   24106 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.793069 logloss:0.524822\n",
            "I0000 00:00:1727923274.119329   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.793069 logloss:0.524822\n",
            "2024-10-03 02:41:14.225628: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [5/20] Score: 0.793069 / 0.79537 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
            "I0000 00:00:1727923274.226021   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727923275.087886   24745 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.747193 logloss:9.11208\n",
            "I0000 00:00:1727923280.307467   24745 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.771701 logloss:3.1681\n",
            "I0000 00:00:1727923285.436783   24745 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.784297 logloss:1.78241\n",
            "I0000 00:00:1727923291.562969   24745 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.790336 logloss:1.21987\n",
            "I0000 00:00:1727923296.969865   24745 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.788898 logloss:1.00402\n",
            "I0000 00:00:1727923303.014055   24745 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.789617 logloss:0.835501\n",
            "I0000 00:00:1727923308.318867   24745 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.790336 logloss:0.762316\n",
            "I0000 00:00:1727923314.008648   24745 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.792494 logloss:0.72347\n",
            "I0000 00:00:1727923319.579614   24745 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.791487 logloss:0.689289\n",
            "I0000 00:00:1727923324.569820   24745 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.794651 logloss:0.673514\n",
            "I0000 00:00:1727923330.682308   24745 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.794363 logloss:0.626383\n",
            "I0000 00:00:1727923335.788229   24745 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.795226 logloss:0.617202\n",
            "I0000 00:00:1727923341.856217   24745 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.79537 logloss:0.598597\n",
            "I0000 00:00:1727923347.091124   24745 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.796951 logloss:0.578801\n",
            "I0000 00:00:1727923352.561322   24745 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.798533 logloss:0.564208\n",
            "I0000 00:00:1727923358.577583   24745 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.796951 logloss:0.553999\n",
            "I0000 00:00:1727923363.630263   24745 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.79767 logloss:0.544729\n",
            "I0000 00:00:1727923370.018297   24745 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.797527 logloss:0.535406\n",
            "I0000 00:00:1727923375.064006   24745 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.798102 logloss:0.535267\n",
            "I0000 00:00:1727923381.279888   24745 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.799252 logloss:0.531258\n",
            "I0000 00:00:1727923386.441408   24745 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.798965 logloss:0.5262\n",
            "I0000 00:00:1727923391.496220   24745 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.799108 logloss:0.520584\n",
            "I0000 00:00:1727923397.813630   24745 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.797958 logloss:0.520526\n",
            "I0000 00:00:1727923403.048382   24745 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.799108 logloss:0.511142\n",
            "I0000 00:00:1727923409.211246   24745 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.799396 logloss:0.511269\n",
            "I0000 00:00:1727923414.342168   24745 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.798821 logloss:0.506584\n",
            "I0000 00:00:1727923419.728626   24745 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.799108 logloss:0.506135\n",
            "I0000 00:00:1727923425.198729   24745 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.79767 logloss:0.505941\n",
            "I0000 00:00:1727923430.496098   24745 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.796664 logloss:0.50589\n",
            "I0000 00:00:1727923436.508332   24745 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.796951 logloss:0.506056\n",
            "I0000 00:00:1727923441.048697   24745 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.79652 logloss:0.505908\n",
            "I0000 00:00:1727923441.048918   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.79652 logloss:0.505908\n",
            "I0000 00:00:1727923441.118039   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "2024-10-03 02:44:01.148809: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [6/20] Score: 0.79652 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
            "I0000 00:00:1727923441.746802   25424 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.725126 logloss:9.90747\n",
            "I0000 00:00:1727923448.744127   25424 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.763744 logloss:3.17128\n",
            "I0000 00:00:1727923454.909877   25424 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.777826 logloss:1.59782\n",
            "I0000 00:00:1727923461.868948   25424 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.779839 logloss:1.16356\n",
            "I0000 00:00:1727923467.997509   25424 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.783146 logloss:0.964897\n",
            "I0000 00:00:1727923475.034413   25424 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.787029 logloss:0.854159\n",
            "I0000 00:00:1727923481.118023   25424 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.787173 logloss:0.760507\n",
            "I0000 00:00:1727923488.356138   25424 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.788323 logloss:0.716451\n",
            "I0000 00:00:1727923494.363735   25424 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.787748 logloss:0.681862\n",
            "I0000 00:00:1727923501.175632   25424 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.789186 logloss:0.656189\n",
            "I0000 00:00:1727923507.365160   25424 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.78933 logloss:0.646389\n",
            "I0000 00:00:1727923514.661681   25424 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.792206 logloss:0.617917\n",
            "I0000 00:00:1727923520.851526   25424 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.79235 logloss:0.598589\n",
            "I0000 00:00:1727923528.224911   25424 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.79235 logloss:0.589709\n",
            "I0000 00:00:1727923534.405292   25424 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.792494 logloss:0.579094\n",
            "I0000 00:00:1727923541.654760   25424 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.790624 logloss:0.56979\n",
            "I0000 00:00:1727923548.139346   25424 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.791343 logloss:0.559885\n",
            "I0000 00:00:1727923555.396621   25424 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.792062 logloss:0.559644\n",
            "I0000 00:00:1727923561.717932   25424 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.792494 logloss:0.555338\n",
            "I0000 00:00:1727923568.662662   25424 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.791056 logloss:0.54552\n",
            "I0000 00:00:1727923574.660624   25424 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.790336 logloss:0.531389\n",
            "I0000 00:00:1727923581.907354   25424 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.789761 logloss:0.530944\n",
            "I0000 00:00:1727923588.000438   25424 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.791631 logloss:0.530411\n",
            "I0000 00:00:1727923595.279589   25424 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.789761 logloss:0.521128\n",
            "I0000 00:00:1727923601.509724   25424 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.79048 logloss:0.520881\n",
            "I0000 00:00:1727923608.840757   25424 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.79235 logloss:0.511962\n",
            "I0000 00:00:1727923615.102549   25424 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.791918 logloss:0.511857\n",
            "I0000 00:00:1727923622.400552   25424 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.792494 logloss:0.50275\n",
            "I0000 00:00:1727923628.807005   25424 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.791918 logloss:0.498049\n",
            "I0000 00:00:1727923636.107640   25424 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.791199 logloss:0.497924\n",
            "I0000 00:00:1727923641.669374   25424 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.791487 logloss:0.497786\n",
            "I0000 00:00:1727923641.669637   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.791487 logloss:0.497786\n",
            "2024-10-03 02:47:21.740748: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [7/20] Score: 0.791487 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 20 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
            "I0000 00:00:1727923641.741080   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727923642.724554   26237 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.73674 logloss:9.48884\n",
            "I0000 00:00:1727923650.102966   26237 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.758391 logloss:3.26713\n",
            "I0000 00:00:1727923657.301497   26237 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.774087 logloss:1.61198\n",
            "I0000 00:00:1727923664.500308   26237 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.781133 logloss:1.11949\n",
            "I0000 00:00:1727923672.473750   26237 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.779408 logloss:0.918668\n",
            "I0000 00:00:1727923679.185650   26237 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.783146 logloss:0.807771\n",
            "I0000 00:00:1727923687.879841   26237 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.784297 logloss:0.737369\n",
            "I0000 00:00:1727923696.630870   26237 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.782427 logloss:0.67655\n",
            "I0000 00:00:1727923703.849554   26237 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.785016 logloss:0.633198\n",
            "I0000 00:00:1727923711.558189   26237 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.784297 logloss:0.623281\n",
            "I0000 00:00:1727923718.720765   26237 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.786598 logloss:0.603009\n",
            "I0000 00:00:1727923727.212161   26237 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.786598 logloss:0.583757\n",
            "I0000 00:00:1727923736.494664   26237 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.786454 logloss:0.572879\n",
            "I0000 00:00:1727923745.687777   26237 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.788036 logloss:0.572752\n",
            "I0000 00:00:1727923753.463645   26237 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.787029 logloss:0.557813\n",
            "I0000 00:00:1727923761.187758   26237 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.785447 logloss:0.548119\n",
            "I0000 00:00:1727923770.676449   26237 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.785447 logloss:0.538713\n",
            "I0000 00:00:1727923778.116669   26237 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.786598 logloss:0.538242\n",
            "I0000 00:00:1727923785.895550   26237 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.786454 logloss:0.533482\n",
            "I0000 00:00:1727923795.900917   26237 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.787029 logloss:0.528477\n",
            "I0000 00:00:1727923804.245810   26237 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.787029 logloss:0.518696\n",
            "I0000 00:00:1727923812.214474   26237 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.78746 logloss:0.518395\n",
            "I0000 00:00:1727923820.961760   26237 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.788755 logloss:0.513955\n",
            "I0000 00:00:1727923827.477539   26237 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.786741 logloss:0.513435\n",
            "I0000 00:00:1727923835.226695   26237 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.788467 logloss:0.508812\n",
            "I0000 00:00:1727923841.929376   26237 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.787029 logloss:0.503651\n",
            "I0000 00:00:1727923851.473236   26237 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.788323 logloss:0.503714\n",
            "I0000 00:00:1727923860.476462   26237 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.788179 logloss:0.503897\n",
            "I0000 00:00:1727923868.681670   26237 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.788036 logloss:0.503922\n",
            "I0000 00:00:1727923878.059242   26237 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.788179 logloss:0.503839\n",
            "I0000 00:00:1727923884.267511   26237 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.788036 logloss:0.499508\n",
            "I0000 00:00:1727923884.272006   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.788036 logloss:0.499508\n",
            "2024-10-03 02:51:24.437716: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [8/20] Score: 0.788036 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
            "I0000 00:00:1727923884.438066   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727923885.458782   27254 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.737127 logloss:9.47489\n",
            "I0000 00:00:1727923892.045204   27254 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.757523 logloss:3.197\n",
            "I0000 00:00:1727923901.301874   27254 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.775093 logloss:1.50507\n",
            "I0000 00:00:1727923909.049055   27254 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.775956 logloss:1.08597\n",
            "I0000 00:00:1727923916.706893   27254 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.779983 logloss:0.911675\n",
            "I0000 00:00:1727923926.098605   27254 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.780846 logloss:0.822766\n",
            "I0000 00:00:1727923933.739682   27254 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.781421 logloss:0.755955\n",
            "I0000 00:00:1727923943.910871   27254 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.781996 logloss:0.72186\n",
            "I0000 00:00:1727923952.097246   27254 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.781277 logloss:0.688343\n",
            "I0000 00:00:1727923958.842976   27254 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.784153 logloss:0.664003\n",
            "I0000 00:00:1727923965.720912   27254 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.785016 logloss:0.648584\n",
            "I0000 00:00:1727923972.512211   27254 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.786454 logloss:0.633516\n",
            "I0000 00:00:1727923979.752938   27254 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.786166 logloss:0.619283\n",
            "I0000 00:00:1727923987.643180   27254 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.784872 logloss:0.599955\n",
            "I0000 00:00:1727923996.955898   27254 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.785879 logloss:0.594207\n",
            "I0000 00:00:1727924003.985042   27254 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.786741 logloss:0.58875\n",
            "I0000 00:00:1727924013.758703   27254 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.786022 logloss:0.583584\n",
            "I0000 00:00:1727924023.040560   27254 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.78516 logloss:0.569221\n",
            "I0000 00:00:1727924030.300920   27254 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.784584 logloss:0.564628\n",
            "I0000 00:00:1727924038.816672   27254 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.785303 logloss:0.559591\n",
            "I0000 00:00:1727924046.928538   27254 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.785016 logloss:0.559494\n",
            "I0000 00:00:1727924055.048034   27254 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.78516 logloss:0.554563\n",
            "I0000 00:00:1727924064.394205   27254 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.785303 logloss:0.545461\n",
            "I0000 00:00:1727924071.056410   27254 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.786598 logloss:0.545442\n",
            "I0000 00:00:1727924080.721611   27254 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.786885 logloss:0.531723\n",
            "I0000 00:00:1727924089.327328   27254 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.78746 logloss:0.522856\n",
            "I0000 00:00:1727924096.862810   27254 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.786598 logloss:0.51853\n",
            "I0000 00:00:1727924105.120801   27254 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.787173 logloss:0.518171\n",
            "I0000 00:00:1727924112.761520   27254 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.786598 logloss:0.517921\n",
            "I0000 00:00:1727924122.079544   27254 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.787029 logloss:0.517433\n",
            "I0000 00:00:1727924129.194308   27254 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.788611 logloss:0.517416\n",
            "I0000 00:00:1727924129.197559   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.788611 logloss:0.517416\n",
            "2024-10-03 02:55:29.397207: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [9/20] Score: 0.788611 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
            "I0000 00:00:1727924129.397541   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727924129.861344   28289 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.762292 logloss:8.56787\n",
            "I0000 00:00:1727924135.550713   28289 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.771557 logloss:3.60776\n",
            "I0000 00:00:1727924141.175569   28289 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.780414 logloss:2.23731\n",
            "I0000 00:00:1727924147.058693   28289 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.78516 logloss:1.77604\n",
            "I0000 00:00:1727924152.931002   28289 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.786885 logloss:1.57097\n",
            "I0000 00:00:1727924158.250101   28289 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.791918 logloss:1.39402\n",
            "I0000 00:00:1727924162.519162   28289 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.791631 logloss:1.25477\n",
            "I0000 00:00:1727924167.082852   28289 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.791631 logloss:1.18078\n",
            "I0000 00:00:1727924172.130323   28289 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.794219 logloss:1.13152\n",
            "I0000 00:00:1727924176.698148   28289 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.794363 logloss:1.07652\n",
            "I0000 00:00:1727924181.339557   28289 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.794219 logloss:1.03053\n",
            "I0000 00:00:1727924185.972559   28289 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.793644 logloss:1.01632\n",
            "I0000 00:00:1727924190.472317   28289 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.79235 logloss:1.00226\n",
            "I0000 00:00:1727924195.685586   28289 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.794219 logloss:0.965095\n",
            "I0000 00:00:1727924200.348293   28289 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.794219 logloss:0.950658\n",
            "I0000 00:00:1727924204.495944   28289 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.793356 logloss:0.931655\n",
            "I0000 00:00:1727924209.738355   28289 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.794219 logloss:0.908507\n",
            "I0000 00:00:1727924214.056551   28289 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.794363 logloss:0.885194\n",
            "I0000 00:00:1727924218.306016   28289 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.793213 logloss:0.88075\n",
            "I0000 00:00:1727924223.907631   28289 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.793356 logloss:0.871177\n",
            "I0000 00:00:1727924227.841910   28289 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.793932 logloss:0.867337\n",
            "I0000 00:00:1727924232.252622   28289 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.794363 logloss:0.853618\n",
            "I0000 00:00:1727924237.410389   28289 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.794651 logloss:0.848931\n",
            "I0000 00:00:1727924241.783149   28289 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.794794 logloss:0.812812\n",
            "I0000 00:00:1727924246.657627   28289 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.795226 logloss:0.794757\n",
            "I0000 00:00:1727924251.540873   28289 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.795082 logloss:0.793751\n",
            "I0000 00:00:1727924255.768772   28289 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.795082 logloss:0.775694\n",
            "I0000 00:00:1727924260.590091   28289 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.795226 logloss:0.771247\n",
            "I0000 00:00:1727924265.286257   28289 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.795082 logloss:0.77108\n",
            "I0000 00:00:1727924269.661726   28289 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.79537 logloss:0.757764\n",
            "I0000 00:00:1727924274.481501   28289 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.794794 logloss:0.757314\n",
            "I0000 00:00:1727924274.487065   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.794794 logloss:0.757314\n",
            "2024-10-03 02:57:54.528041: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [10/20] Score: 0.794794 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
            "I0000 00:00:1727924274.536203   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727924275.541499   28884 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.75842 logloss:8.70741\n",
            "I0000 00:00:1727924281.581450   28884 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.771557 logloss:3.24436\n",
            "I0000 00:00:1727924288.687928   28884 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.781421 logloss:1.74029\n",
            "I0000 00:00:1727924294.637577   28884 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.784297 logloss:1.26227\n",
            "I0000 00:00:1727924301.418420   28884 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.786741 logloss:1.07311\n",
            "I0000 00:00:1727924307.273126   28884 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.791056 logloss:0.959436\n",
            "I0000 00:00:1727924314.450667   28884 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.789905 logloss:0.857291\n",
            "I0000 00:00:1727924320.703652   28884 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.790912 logloss:0.780152\n",
            "I0000 00:00:1727924327.932133   28884 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.792206 logloss:0.698946\n",
            "I0000 00:00:1727924334.051108   28884 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.791199 logloss:0.660538\n",
            "I0000 00:00:1727924341.016292   28884 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.79235 logloss:0.650123\n",
            "I0000 00:00:1727924346.925828   28884 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.790768 logloss:0.630646\n",
            "I0000 00:00:1727924354.146894   28884 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.790624 logloss:0.626053\n",
            "I0000 00:00:1727924360.444673   28884 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.792206 logloss:0.621454\n",
            "I0000 00:00:1727924367.425390   28884 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.791487 logloss:0.607182\n",
            "I0000 00:00:1727924373.569406   28884 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.79048 logloss:0.601966\n",
            "I0000 00:00:1727924381.016332   28884 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.791631 logloss:0.582666\n",
            "I0000 00:00:1727924387.220630   28884 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.791056 logloss:0.573143\n",
            "I0000 00:00:1727924394.289455   28884 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.791199 logloss:0.55883\n",
            "I0000 00:00:1727924400.376320   28884 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.790624 logloss:0.549709\n",
            "I0000 00:00:1727924407.425251   28884 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.79235 logloss:0.545344\n",
            "I0000 00:00:1727924413.711199   28884 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.791775 logloss:0.53635\n",
            "I0000 00:00:1727924421.179737   28884 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.792925 logloss:0.535683\n",
            "I0000 00:00:1727924427.523098   28884 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.792637 logloss:0.53108\n",
            "I0000 00:00:1727924434.700287   28884 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.793788 logloss:0.530674\n",
            "I0000 00:00:1727924441.002302   28884 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.792925 logloss:0.530373\n",
            "I0000 00:00:1727924447.880179   28884 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.793213 logloss:0.530055\n",
            "I0000 00:00:1727924454.241037   28884 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.792206 logloss:0.52566\n",
            "I0000 00:00:1727924461.581482   28884 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.792494 logloss:0.525254\n",
            "I0000 00:00:1727924467.735988   28884 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.792062 logloss:0.520404\n",
            "I0000 00:00:1727924474.138950   28884 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.791775 logloss:0.520292\n",
            "I0000 00:00:1727924474.139191   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.791775 logloss:0.520292\n",
            "2024-10-03 03:01:14.217192: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [11/20] Score: 0.791775 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
            "I0000 00:00:1727924474.221208   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727924474.886871   29697 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.732869 logloss:9.62839\n",
            "I0000 00:00:1727924481.397048   29697 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.753762 logloss:3.31058\n",
            "I0000 00:00:1727924489.138052   29697 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.771067 logloss:1.59462\n",
            "I0000 00:00:1727924495.568052   29697 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.778832 logloss:1.14072\n",
            "I0000 00:00:1727924502.811138   29697 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.776963 logloss:0.960988\n",
            "I0000 00:00:1727924509.215322   29697 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.779551 logloss:0.857059\n",
            "I0000 00:00:1727924516.467370   29697 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.780558 logloss:0.789262\n",
            "I0000 00:00:1727924522.864056   29697 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.782427 logloss:0.741695\n",
            "I0000 00:00:1727924530.473065   29697 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.780846 logloss:0.711812\n",
            "I0000 00:00:1727924536.742092   29697 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.782715 logloss:0.69548\n",
            "I0000 00:00:1727924544.603731   29697 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.784872 logloss:0.671373\n",
            "I0000 00:00:1727924551.696584   29697 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.783865 logloss:0.64727\n",
            "I0000 00:00:1727924559.007168   29697 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.785879 logloss:0.642127\n",
            "I0000 00:00:1727924566.353639   29697 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.785016 logloss:0.627742\n",
            "I0000 00:00:1727924572.920451   29697 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.785447 logloss:0.621896\n",
            "I0000 00:00:1727924580.708971   29697 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.784728 logloss:0.617613\n",
            "I0000 00:00:1727924587.455384   29697 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.784009 logloss:0.608248\n",
            "I0000 00:00:1727924594.860485   29697 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.785735 logloss:0.602815\n",
            "I0000 00:00:1727924601.400338   29697 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.78516 logloss:0.593381\n",
            "I0000 00:00:1727924608.452735   29697 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.78516 logloss:0.584002\n",
            "I0000 00:00:1727924614.816672   29697 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.786022 logloss:0.583524\n",
            "I0000 00:00:1727924622.333674   29697 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.785016 logloss:0.578415\n",
            "I0000 00:00:1727924628.597043   29697 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.785879 logloss:0.57837\n",
            "I0000 00:00:1727924635.870679   29697 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.786166 logloss:0.577593\n",
            "I0000 00:00:1727924642.451743   29697 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.785879 logloss:0.577885\n",
            "I0000 00:00:1727924649.919816   29697 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.787317 logloss:0.577452\n",
            "I0000 00:00:1727924656.300507   29697 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.786741 logloss:0.567966\n",
            "I0000 00:00:1727924663.769641   29697 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.785735 logloss:0.563151\n",
            "I0000 00:00:1727924670.654779   29697 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.786166 logloss:0.558482\n",
            "I0000 00:00:1727924677.902777   29697 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.786454 logloss:0.558383\n",
            "I0000 00:00:1727924684.850963   29697 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.786022 logloss:0.558383\n",
            "I0000 00:00:1727924684.851946   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.786022 logloss:0.558383\n",
            "2024-10-03 03:04:45.094264: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [12/20] Score: 0.786022 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
            "I0000 00:00:1727924685.108983   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727924686.055834   30556 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.732482 logloss:9.64234\n",
            "I0000 00:00:1727924691.636364   30556 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.767072 logloss:3.11121\n",
            "I0000 00:00:1727924697.684068   30556 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.777251 logloss:1.60618\n",
            "I0000 00:00:1727924703.803293   30556 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.780127 logloss:1.18994\n",
            "I0000 00:00:1727924709.168318   30556 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.785879 logloss:1.03707\n",
            "I0000 00:00:1727924715.366032   30556 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.786022 logloss:0.933098\n",
            "I0000 00:00:1727924720.708632   30556 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.789617 logloss:0.817331\n",
            "I0000 00:00:1727924727.164180   30556 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.788755 logloss:0.757972\n",
            "I0000 00:00:1727924732.305579   30556 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.788323 logloss:0.709975\n",
            "I0000 00:00:1727924738.687834   30556 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.790336 logloss:0.663218\n",
            "I0000 00:00:1727924744.071137   30556 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.790049 logloss:0.635515\n",
            "I0000 00:00:1727924749.169762   30556 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.790768 logloss:0.616083\n",
            "I0000 00:00:1727924755.574151   30556 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.789042 logloss:0.592395\n",
            "I0000 00:00:1727924760.885748   30556 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.789617 logloss:0.582874\n",
            "I0000 00:00:1727924767.251906   30556 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.790624 logloss:0.577576\n",
            "I0000 00:00:1727924772.668714   30556 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.793356 logloss:0.57183\n",
            "I0000 00:00:1727924778.947289   30556 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.791487 logloss:0.55809\n",
            "I0000 00:00:1727924784.257539   30556 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.791775 logloss:0.557784\n",
            "I0000 00:00:1727924790.298495   30556 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.791056 logloss:0.552639\n",
            "I0000 00:00:1727924796.198980   30556 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.792062 logloss:0.537424\n",
            "I0000 00:00:1727924801.653911   30556 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.792206 logloss:0.537266\n",
            "I0000 00:00:1727924808.275040   30556 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.791775 logloss:0.523058\n",
            "I0000 00:00:1727924813.488567   30556 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.792494 logloss:0.522842\n",
            "I0000 00:00:1727924819.932646   30556 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.793213 logloss:0.522597\n",
            "I0000 00:00:1727924825.291087   30556 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.791487 logloss:0.517774\n",
            "I0000 00:00:1727924831.487083   30556 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.792206 logloss:0.513015\n",
            "I0000 00:00:1727924836.972511   30556 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.792637 logloss:0.512682\n",
            "I0000 00:00:1727924842.628984   30556 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.792494 logloss:0.512682\n",
            "I0000 00:00:1727924848.998875   30556 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.793069 logloss:0.507299\n",
            "I0000 00:00:1727924854.451003   30556 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.79235 logloss:0.507346\n",
            "I0000 00:00:1727924860.378570   30556 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.793069 logloss:0.507704\n",
            "I0000 00:00:1727924860.378808   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.793069 logloss:0.507704\n",
            "2024-10-03 03:07:40.455857: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [13/20] Score: 0.793069 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 2 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
            "I0000 00:00:1727924860.456208   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727924860.969869   31265 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.773906 logloss:8.14924\n",
            "I0000 00:00:1727924866.096379   31265 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.777922 logloss:3.86292\n",
            "I0000 00:00:1727924872.195596   31265 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.786885 logloss:2.41635\n",
            "I0000 00:00:1727924877.237394   31265 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.791775 logloss:1.7802\n",
            "I0000 00:00:1727924881.923858   31265 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.789905 logloss:1.51882\n",
            "I0000 00:00:1727924887.873838   31265 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.793788 logloss:1.33281\n",
            "I0000 00:00:1727924892.819073   31265 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.792781 logloss:1.26172\n",
            "I0000 00:00:1727924898.714990   31265 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.794363 logloss:1.19853\n",
            "I0000 00:00:1727924903.779157   31265 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.794651 logloss:1.10676\n",
            "I0000 00:00:1727924909.179237   31265 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.794938 logloss:1.06458\n",
            "I0000 00:00:1727924914.853386   31265 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.796664 logloss:1.02711\n",
            "I0000 00:00:1727924919.808303   31265 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.795801 logloss:1.00346\n",
            "I0000 00:00:1727924925.841818   31265 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.794075 logloss:0.975822\n",
            "I0000 00:00:1727924930.622500   31265 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.796664 logloss:0.929694\n",
            "I0000 00:00:1727924935.529334   31265 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.79537 logloss:0.911675\n",
            "I0000 00:00:1727924941.428033   31265 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.796664 logloss:0.865803\n",
            "I0000 00:00:1727924946.369653   31265 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.797239 logloss:0.842754\n",
            "I0000 00:00:1727924952.410256   31265 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.796232 logloss:0.833529\n",
            "I0000 00:00:1727924957.557644   31265 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.79537 logloss:0.819253\n",
            "I0000 00:00:1727924962.968737   31265 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.795945 logloss:0.809642\n",
            "I0000 00:00:1727924968.040938   31265 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.796232 logloss:0.800997\n",
            "I0000 00:00:1727924973.177450   31265 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.797239 logloss:0.782889\n",
            "I0000 00:00:1727924979.276235   31265 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.795801 logloss:0.778846\n",
            "I0000 00:00:1727924984.071761   31265 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.797095 logloss:0.779118\n",
            "I0000 00:00:1727924989.473594   31265 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.796089 logloss:0.75969\n",
            "I0000 00:00:1727924995.330361   31265 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.796232 logloss:0.746651\n",
            "I0000 00:00:1727925000.187252   31265 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.79652 logloss:0.736938\n",
            "I0000 00:00:1727925006.117358   31265 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.79652 logloss:0.723462\n",
            "I0000 00:00:1727925011.055129   31265 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.79652 logloss:0.714275\n",
            "I0000 00:00:1727925016.632543   31265 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.796664 logloss:0.709944\n",
            "I0000 00:00:1727925021.344143   31265 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.796376 logloss:0.700538\n",
            "I0000 00:00:1727925021.344413   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.796376 logloss:0.700538\n",
            "2024-10-03 03:10:21.369382: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [14/20] Score: 0.796376 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 25 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
            "I0000 00:00:1727925021.373435   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727925021.978936   31936 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.746032 logloss:9.15394\n",
            "I0000 00:00:1727925027.551393   31936 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.762297 logloss:3.20766\n",
            "I0000 00:00:1727925034.386559   31936 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.779408 logloss:1.74155\n",
            "I0000 00:00:1727925040.099894   31936 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.779551 logloss:1.2772\n",
            "I0000 00:00:1727925047.037717   31936 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.784153 logloss:1.07353\n",
            "I0000 00:00:1727925052.975982   31936 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.787604 logloss:0.930019\n",
            "I0000 00:00:1727925059.525754   31936 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.788611 logloss:0.841229\n",
            "I0000 00:00:1727925065.259150   31936 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.788179 logloss:0.769749\n",
            "I0000 00:00:1727925072.148245   31936 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.792062 logloss:0.682787\n",
            "I0000 00:00:1727925077.619364   31936 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.790049 logloss:0.663168\n",
            "I0000 00:00:1727925084.112566   31936 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.790193 logloss:0.643769\n",
            "I0000 00:00:1727925089.701252   31936 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.791056 logloss:0.633369\n",
            "I0000 00:00:1727925096.171862   31936 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.791631 logloss:0.600017\n",
            "I0000 00:00:1727925102.576037   31936 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.791918 logloss:0.581349\n",
            "I0000 00:00:1727925108.511726   31936 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.792206 logloss:0.567459\n",
            "I0000 00:00:1727925115.235383   31936 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.792637 logloss:0.567321\n",
            "I0000 00:00:1727925121.011371   31936 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.791056 logloss:0.561278\n",
            "I0000 00:00:1727925127.918601   31936 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.791918 logloss:0.556244\n",
            "I0000 00:00:1727925133.613832   31936 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.791056 logloss:0.556114\n",
            "I0000 00:00:1727925139.890353   31936 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.791487 logloss:0.55101\n",
            "I0000 00:00:1727925145.361121   31936 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.792206 logloss:0.551321\n",
            "I0000 00:00:1727925152.372349   31936 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.792494 logloss:0.546203\n",
            "I0000 00:00:1727925158.147696   31936 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.792781 logloss:0.536526\n",
            "I0000 00:00:1727925164.734723   31936 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.793788 logloss:0.536012\n",
            "I0000 00:00:1727925170.322653   31936 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.793644 logloss:0.526846\n",
            "I0000 00:00:1727925177.075174   31936 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.7935 logloss:0.526657\n",
            "I0000 00:00:1727925182.907919   31936 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.793788 logloss:0.526493\n",
            "I0000 00:00:1727925189.007711   31936 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.793213 logloss:0.526343\n",
            "I0000 00:00:1727925195.558296   31936 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.792637 logloss:0.526215\n",
            "I0000 00:00:1727925201.537421   31936 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.793932 logloss:0.525972\n",
            "I0000 00:00:1727925207.779220   31936 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.7935 logloss:0.525797\n",
            "I0000 00:00:1727925207.779504   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.7935 logloss:0.525797\n",
            "2024-10-03 03:13:27.852348: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [15/20] Score: 0.7935 / 0.79652 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 3 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"STANDARD_DEVIATION\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
            "I0000 00:00:1727925207.855216   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727925208.445045   32723 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.746806 logloss:9.12603\n",
            "I0000 00:00:1727925213.537981   32723 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.782841 logloss:3.76257\n",
            "I0000 00:00:1727925219.831050   32723 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.790336 logloss:2.16805\n",
            "I0000 00:00:1727925225.351869   32723 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.792925 logloss:1.69202\n",
            "I0000 00:00:1727925231.506626   32723 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.793932 logloss:1.48046\n",
            "I0000 00:00:1727925236.328942   32723 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.794794 logloss:1.36603\n",
            "I0000 00:00:1727925242.000620   32723 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.793788 logloss:1.29451\n",
            "I0000 00:00:1727925248.069046   32723 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.795226 logloss:1.19498\n",
            "I0000 00:00:1727925253.234985   32723 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.798246 logloss:1.10881\n",
            "I0000 00:00:1727925259.545414   32723 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.796951 logloss:1.07688\n",
            "I0000 00:00:1727925265.004258   32723 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.796808 logloss:1.03045\n",
            "I0000 00:00:1727925271.321444   32723 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.797239 logloss:1.00698\n",
            "I0000 00:00:1727925276.429720   32723 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.795082 logloss:0.973619\n",
            "I0000 00:00:1727925282.326584   32723 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.794219 logloss:0.950975\n",
            "I0000 00:00:1727925288.259993   32723 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.794507 logloss:0.931129\n",
            "I0000 00:00:1727925293.825584   32723 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.794363 logloss:0.898477\n",
            "I0000 00:00:1727925300.036267   32723 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.792637 logloss:0.865321\n",
            "I0000 00:00:1727925305.393411   32723 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.793932 logloss:0.837631\n",
            "I0000 00:00:1727925312.000071   32723 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.794075 logloss:0.819182\n",
            "I0000 00:00:1727925317.307771   32723 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.795513 logloss:0.804832\n",
            "I0000 00:00:1727925323.760683   32723 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.79652 logloss:0.800018\n",
            "I0000 00:00:1727925328.948098   32723 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.795801 logloss:0.781569\n",
            "I0000 00:00:1727925334.738381   32723 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.795513 logloss:0.772722\n",
            "I0000 00:00:1727925340.817820   32723 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.795513 logloss:0.767782\n",
            "I0000 00:00:1727925346.114908   32723 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.79537 logloss:0.762802\n",
            "I0000 00:00:1727925352.302998   32723 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.79537 logloss:0.762251\n",
            "I0000 00:00:1727925357.573145   32723 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.79652 logloss:0.757847\n",
            "I0000 00:00:1727925364.069391   32723 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.795945 logloss:0.739585\n",
            "I0000 00:00:1727925369.602254   32723 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.797239 logloss:0.730379\n",
            "I0000 00:00:1727925375.979204   32723 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.797958 logloss:0.726249\n",
            "I0000 00:00:1727925381.011207   32723 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.797095 logloss:0.712519\n",
            "I0000 00:00:1727925381.011384   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.797095 logloss:0.712519\n",
            "I0000 00:00:1727925381.037191   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "2024-10-03 03:16:21.109310: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [16/20] Score: 0.797095 / 0.797095 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 5 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"CART\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
            "I0000 00:00:1727925381.591563   33456 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.767712 logloss:8.37251\n",
            "I0000 00:00:1727925386.913595   33456 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.779659 logloss:3.8163\n",
            "I0000 00:00:1727925392.795859   33456 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.785879 logloss:2.30055\n",
            "I0000 00:00:1727925397.949729   33456 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.789761 logloss:1.80107\n",
            "I0000 00:00:1727925403.942275   33456 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.790049 logloss:1.52768\n",
            "I0000 00:00:1727925408.942516   33456 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.791918 logloss:1.37926\n",
            "I0000 00:00:1727925414.485882   33456 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.793644 logloss:1.21935\n",
            "I0000 00:00:1727925420.171490   33456 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.792062 logloss:1.15212\n",
            "I0000 00:00:1727925425.236548   33456 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.792494 logloss:1.10427\n",
            "I0000 00:00:1727925431.677654   33456 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.793213 logloss:1.07157\n",
            "I0000 00:00:1727925436.736688   33456 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.792781 logloss:1.04372\n",
            "I0000 00:00:1727925442.683598   33456 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.791343 logloss:1.00724\n",
            "I0000 00:00:1727925447.943617   33456 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.793213 logloss:0.947421\n",
            "I0000 00:00:1727925452.910091   33456 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.793644 logloss:0.929492\n",
            "I0000 00:00:1727925459.239739   33456 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.7935 logloss:0.920023\n",
            "I0000 00:00:1727925464.506020   33456 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.793644 logloss:0.902134\n",
            "I0000 00:00:1727925470.879068   33456 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.793069 logloss:0.887966\n",
            "I0000 00:00:1727925476.257971   33456 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.792637 logloss:0.873656\n",
            "I0000 00:00:1727925482.368098   33456 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.791918 logloss:0.850525\n",
            "I0000 00:00:1727925487.950315   33456 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.79235 logloss:0.832089\n",
            "I0000 00:00:1727925493.254580   33456 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.7935 logloss:0.827391\n",
            "I0000 00:00:1727925499.257576   33456 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.792781 logloss:0.795551\n",
            "I0000 00:00:1727925504.502319   33456 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.792062 logloss:0.785652\n",
            "I0000 00:00:1727925510.907437   33456 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.791775 logloss:0.781098\n",
            "I0000 00:00:1727925515.969411   33456 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.793213 logloss:0.781363\n",
            "I0000 00:00:1727925521.854925   33456 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.795513 logloss:0.776823\n",
            "I0000 00:00:1727925527.359883   33456 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.793932 logloss:0.763484\n",
            "I0000 00:00:1727925532.562919   33456 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.793644 logloss:0.749496\n",
            "I0000 00:00:1727925538.673929   33456 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.794075 logloss:0.740108\n",
            "I0000 00:00:1727925543.888510   33456 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.792925 logloss:0.731174\n",
            "I0000 00:00:1727925549.720869   33456 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.793069 logloss:0.727081\n",
            "I0000 00:00:1727925549.721041   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.793069 logloss:0.727081\n",
            "2024-10-03 03:19:09.743108: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [17/20] Score: 0.793069 / 0.797095 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"MIN_MAX\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 16 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
            "I0000 00:00:1727925549.743638   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727925550.397142   34169 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.758808 logloss:8.69346\n",
            "I0000 00:00:1727925555.752393   34169 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.776331 logloss:3.39594\n",
            "I0000 00:00:1727925562.048572   34169 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.785591 logloss:1.93191\n",
            "I0000 00:00:1727925567.639463   34169 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.788323 logloss:1.51344\n",
            "I0000 00:00:1727925573.520917   34169 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.78933 logloss:1.30593\n",
            "I0000 00:00:1727925579.792691   34169 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.790912 logloss:1.16255\n",
            "I0000 00:00:1727925585.376975   34169 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.788755 logloss:1.05827\n",
            "I0000 00:00:1727925591.847293   34169 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.791631 logloss:0.997291\n",
            "I0000 00:00:1727925597.349734   34169 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.791918 logloss:0.960383\n",
            "I0000 00:00:1727925604.199232   34169 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.792781 logloss:0.895394\n",
            "I0000 00:00:1727925609.860725   34169 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.792494 logloss:0.830541\n",
            "I0000 00:00:1727925616.339089   34169 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.793356 logloss:0.806485\n",
            "I0000 00:00:1727925621.997269   34169 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.79235 logloss:0.792502\n",
            "I0000 00:00:1727925628.391208   34169 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.792494 logloss:0.767659\n",
            "I0000 00:00:1727925634.149025   34169 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.792637 logloss:0.754091\n",
            "I0000 00:00:1727925639.875229   34169 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.793788 logloss:0.740014\n",
            "I0000 00:00:1727925646.228328   34169 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.794651 logloss:0.721749\n",
            "I0000 00:00:1727925651.543608   34169 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.794938 logloss:0.698356\n",
            "I0000 00:00:1727925658.025306   34169 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.795082 logloss:0.689235\n",
            "I0000 00:00:1727925663.409826   34169 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.793788 logloss:0.684152\n",
            "I0000 00:00:1727925670.033195   34169 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.794363 logloss:0.665889\n",
            "I0000 00:00:1727925675.283658   34169 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.795513 logloss:0.661761\n",
            "I0000 00:00:1727925681.604291   34169 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.79537 logloss:0.661701\n",
            "I0000 00:00:1727925687.254473   34169 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.794938 logloss:0.652692\n",
            "I0000 00:00:1727925692.969456   34169 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.794507 logloss:0.639368\n",
            "I0000 00:00:1727925699.267989   34169 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.793932 logloss:0.639298\n",
            "I0000 00:00:1727925704.766226   34169 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.794363 logloss:0.63413\n",
            "I0000 00:00:1727925711.497597   34169 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.794938 logloss:0.634288\n",
            "I0000 00:00:1727925716.865538   34169 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.794794 logloss:0.620393\n",
            "I0000 00:00:1727925723.761510   34169 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.795226 logloss:0.619861\n",
            "I0000 00:00:1727925728.844473   34169 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.794507 logloss:0.61477\n",
            "I0000 00:00:1727925728.844638   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.794507 logloss:0.61477\n",
            "2024-10-03 03:22:08.908657: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [18/20] Score: 0.794507 / 0.797095 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
            "I0000 00:00:1727925728.909068   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727925729.584622   34924 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.757646 logloss:8.73532\n",
            "I0000 00:00:1727925735.677672   34924 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.773582 logloss:3.57283\n",
            "I0000 00:00:1727925740.372098   34924 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.784728 logloss:2.36691\n",
            "I0000 00:00:1727925745.459771   34924 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.788611 logloss:1.80687\n",
            "I0000 00:00:1727925751.126028   34924 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.790624 logloss:1.56586\n",
            "I0000 00:00:1727925755.936088   34924 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.791631 logloss:1.41836\n",
            "I0000 00:00:1727925762.211710   34924 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.793644 logloss:1.29232\n",
            "I0000 00:00:1727925767.167190   34924 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.794075 logloss:1.23187\n",
            "I0000 00:00:1727925772.408457   34924 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.792637 logloss:1.11852\n",
            "I0000 00:00:1727925778.179294   34924 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.793644 logloss:1.08191\n",
            "I0000 00:00:1727925783.056968   34924 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.793932 logloss:1.04428\n",
            "I0000 00:00:1727925788.807873   34924 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.793788 logloss:1.02695\n",
            "I0000 00:00:1727925794.131702   34924 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.794507 logloss:1.00319\n",
            "I0000 00:00:1727925799.459295   34924 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.7935 logloss:0.97113\n",
            "I0000 00:00:1727925805.085646   34924 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.793356 logloss:0.947771\n",
            "I0000 00:00:1727925809.865349   34924 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.793213 logloss:0.924985\n",
            "I0000 00:00:1727925815.663976   34924 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.793644 logloss:0.887414\n",
            "I0000 00:00:1727925820.579685   34924 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.794075 logloss:0.873837\n",
            "I0000 00:00:1727925826.083428   34924 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.792925 logloss:0.846881\n",
            "I0000 00:00:1727925831.415120   34924 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.794219 logloss:0.833132\n",
            "I0000 00:00:1727925836.190380   34924 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.793213 logloss:0.833472\n",
            "I0000 00:00:1727925842.416247   34924 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.792494 logloss:0.823986\n",
            "I0000 00:00:1727925847.166203   34924 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.79235 logloss:0.819578\n",
            "I0000 00:00:1727925852.592144   34924 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.792781 logloss:0.810137\n",
            "I0000 00:00:1727925858.328752   34924 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.791775 logloss:0.796499\n",
            "I0000 00:00:1727925863.145479   34924 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.79235 logloss:0.796337\n",
            "I0000 00:00:1727925869.087862   34924 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.792781 logloss:0.787759\n",
            "I0000 00:00:1727925874.146662   34924 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.794075 logloss:0.76911\n",
            "I0000 00:00:1727925879.552564   34924 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.793788 logloss:0.759833\n",
            "I0000 00:00:1727925885.112275   34924 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.793356 logloss:0.755904\n",
            "I0000 00:00:1727925889.684855   34924 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.793213 logloss:0.737196\n",
            "I0000 00:00:1727925889.685350   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.793213 logloss:0.737196\n",
            "2024-10-03 03:24:49.715925: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [19/20] Score: 0.793213 / 0.797095 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 4 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"BINARY\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 40 } }\n",
            "I0000 00:00:1727925889.719951   20297 random_forest.cc:428] Training random forest on 6954 example(s) and 13 feature(s).\n",
            "I0000 00:00:1727925890.233472   35607 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.754162 logloss:8.86091\n",
            "I0000 00:00:1727925895.843858   35607 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.773003 logloss:3.36861\n",
            "I0000 00:00:1727925900.614871   35607 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.781277 logloss:1.91821\n",
            "I0000 00:00:1727925905.744110   35607 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.785016 logloss:1.47647\n",
            "I0000 00:00:1727925910.733217   35607 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.786741 logloss:1.26842\n",
            "I0000 00:00:1727925915.229742   35607 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.790912 logloss:1.14346\n",
            "I0000 00:00:1727925920.789357   35607 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.789474 logloss:1.06463\n",
            "I0000 00:00:1727925925.199540   35607 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.792781 logloss:0.979744\n",
            "I0000 00:00:1727925929.825218   35607 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.792925 logloss:0.942494\n",
            "I0000 00:00:1727925935.651786   35607 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.794651 logloss:0.895067\n",
            "I0000 00:00:1727925940.093549   35607 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.795082 logloss:0.862177\n",
            "I0000 00:00:1727925945.245728   35607 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.794363 logloss:0.829416\n",
            "I0000 00:00:1727925950.521369   35607 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.794938 logloss:0.801595\n",
            "I0000 00:00:1727925954.883154   35607 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.792781 logloss:0.767503\n",
            "I0000 00:00:1727925960.735120   35607 random_forest.cc:812] Training of tree  141/300 (tree index:140) done accuracy:0.793069 logloss:0.761547\n",
            "I0000 00:00:1727925965.320489   35607 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.793788 logloss:0.757684\n",
            "I0000 00:00:1727925969.878866   35607 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.792781 logloss:0.73864\n",
            "I0000 00:00:1727925975.443391   35607 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.793644 logloss:0.729799\n",
            "I0000 00:00:1727925979.871050   35607 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.793356 logloss:0.712228\n",
            "I0000 00:00:1727925984.847495   35607 random_forest.cc:812] Training of tree  191/300 (tree index:190) done accuracy:0.7935 logloss:0.699015\n",
            "I0000 00:00:1727925989.919859   35607 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.794075 logloss:0.680775\n",
            "I0000 00:00:1727925994.689467   35607 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.793069 logloss:0.676929\n",
            "I0000 00:00:1727926000.147441   35607 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.793213 logloss:0.658331\n",
            "I0000 00:00:1727926005.004455   35607 random_forest.cc:812] Training of tree  231/300 (tree index:230) done accuracy:0.792206 logloss:0.653246\n",
            "I0000 00:00:1727926009.499421   35607 random_forest.cc:812] Training of tree  241/300 (tree index:240) done accuracy:0.791918 logloss:0.64866\n",
            "I0000 00:00:1727926014.939017   35607 random_forest.cc:812] Training of tree  251/300 (tree index:250) done accuracy:0.793213 logloss:0.643818\n",
            "I0000 00:00:1727926019.236132   35607 random_forest.cc:812] Training of tree  261/300 (tree index:260) done accuracy:0.792637 logloss:0.634496\n",
            "I0000 00:00:1727926023.744867   35607 random_forest.cc:812] Training of tree  271/300 (tree index:270) done accuracy:0.7935 logloss:0.634041\n",
            "I0000 00:00:1727926029.087995   35607 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.7935 logloss:0.628917\n",
            "I0000 00:00:1727926033.681956   35607 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.793644 logloss:0.624287\n",
            "I0000 00:00:1727926038.270751   35607 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.793356 logloss:0.62355\n",
            "I0000 00:00:1727926038.275917   20297 random_forest.cc:892] Final OOB metrics: accuracy:0.793356 logloss:0.62355\n",
            "2024-10-03 03:27:18.365216: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:577] [20/20] Score: 0.793356 / 0.797095 HParams: fields { name: \"split_axis\" value { categorical: \"SPARSE_OBLIQUE\" } } fields { name: \"sparse_oblique_projection_density_factor\" value { real: 1 } } fields { name: \"sparse_oblique_normalization\" value { categorical: \"NONE\" } } fields { name: \"sparse_oblique_weights\" value { categorical: \"CONTINUOUS\" } } fields { name: \"categorical_algorithm\" value { categorical: \"RANDOM\" } } fields { name: \"winner_take_all\" value { categorical: \"true\" } } fields { name: \"max_depth\" value { integer: 12 } } fields { name: \"min_examples\" value { integer: 1 } }\n",
            "2024-10-03 03:27:18.466576: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:218] Best hyperparameters:\n",
            "fields {\n",
            "  name: \"split_axis\"\n",
            "  value {\n",
            "    categorical: \"SPARSE_OBLIQUE\"\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"sparse_oblique_projection_density_factor\"\n",
            "  value {\n",
            "    real: 5\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"sparse_oblique_normalization\"\n",
            "  value {\n",
            "    categorical: \"NONE\"\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"sparse_oblique_weights\"\n",
            "  value {\n",
            "    categorical: \"CONTINUOUS\"\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"categorical_algorithm\"\n",
            "  value {\n",
            "    categorical: \"CART\"\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"winner_take_all\"\n",
            "  value {\n",
            "    categorical: \"true\"\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"max_depth\"\n",
            "  value {\n",
            "    integer: 16\n",
            "  }\n",
            "}\n",
            "fields {\n",
            "  name: \"min_examples\"\n",
            "  value {\n",
            "    integer: 40\n",
            "  }\n",
            "}\n",
            "\n",
            "I0000 00:00:1727926038.466969   20296 kernel.cc:920] Export model in log directory: /tmp/tmpch2zaac5 with prefix 7a5574d5e1a14a05\n",
            "I0000 00:00:1727926038.611509   20296 kernel.cc:938] Save model in resources\n",
            "I0000 00:00:1727926038.794057     401 abstract_model.cc:833] Model self evaluation:\n",
            "Number of predictions (without weights): 6954\n",
            "Number of predictions (with weights): 6954\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.797095  CI95[W][0.788999 0.805007]\n",
            "LogLoss: : 0.712519\n",
            "ErrorRate: : 0.202905\n",
            "\n",
            "Default Accuracy: : 0.505896\n",
            "Default LogLoss: : 0.693078\n",
            "Default ErrorRate: : 0.494104\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "      1     2\n",
            "1  2674   762\n",
            "2   649  2869\n",
            "Total: 6954\n",
            "\n",
            "\n",
            "2024-10-03 03:27:18.883760: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /tmp/tmpch2zaac5/model/ with prefix 7a5574d5e1a14a05\n",
            "I0000 00:00:1727926039.141687     401 decision_forest.cc:761] Model loaded with 300 root(s), 64144 node(s), and 13 input feature(s).\n",
            "I0000 00:00:1727926039.142006     401 abstract_model.cc:1323] Engine \"RandomForestGeneric\" built\n",
            "2024-10-03 03:27:19.142050: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model trained in 1:03:49.728018\n",
            "Compiling model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7c03ac2f4d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model compiled.\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - accuracy: 0.8114\n"
          ]
        }
      ],
      "source": [
        "tuner = tfdf.tuner.RandomSearch(num_trials=20, use_predefined_hps=True)\n",
        "\n",
        "rf = tfdf.keras.RandomForestModel(tuner=tuner, compute_oob_performances=True)\n",
        "rf.fit(train_ds, verbose=2)\n",
        "rf.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "evaluation = rf.evaluate(valid_ds, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXjPhTLW5cTq"
      },
      "source": [
        "## Model interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF5jWYia5Qon"
      },
      "source": [
        "Now that we've built out our model let's assess the use of our features within it. We'll start with feature importances here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "uFKtWttt6R3G",
        "outputId": "e6e34c45-742c-43a3-dfea-6b18210b947f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"000d14ce-8ba3-4b2e-9f27-ba68ea6a4c8b\" class=\"plotly-graph-div\" style=\"height:650px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"000d14ce-8ba3-4b2e-9f27-ba68ea6a4c8b\")) {                    Plotly.newPlot(                        \"000d14ce-8ba3-4b2e-9f27-ba68ea6a4c8b\",                        [{\"name\":\"Accuracy\",\"x\":[1,11,21,31,41,51,61,71,81,91,101,111,121,131,141,151,161,171,181,191,201,211,221,231,241,251,261,271,281,291,300],\"y\":[0.7468060394889663,0.7828414351851852,0.7903364969801553,0.7929249352890423,0.7939315501869427,0.7947943629565718,0.7937877480586712,0.7952257693413862,0.7982456140350878,0.7969513948806443,0.7968075927523728,0.7972389991371872,0.7950819672131147,0.7942191544434858,0.7945067587000287,0.7943629565717573,0.7926373310324992,0.7939315501869427,0.7940753523152143,0.7955133735979293,0.7965199884958297,0.7958009778544722,0.7955133735979293,0.7955133735979293,0.7953695714696577,0.7953695714696577,0.7965199884958297,0.7959447799827437,0.7972389991371872,0.7979580097785447,0.7970951970089157],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Log-loss\",\"x\":[1,11,21,31,41,51,61,71,81,91,101,111,121,131,141,151,161,171,181,191,201,211,221,231,241,251,261,271,281,291,300],\"y\":[9.126034895025203,3.7625745315109036,2.1680502733946927,1.6920191553400694,1.4804593249855453,1.366030653158665,1.2945144939859636,1.1949838333673988,1.1088103330971366,1.0768772102099555,1.0304456335445022,1.0069808081799017,0.9736192950303619,0.9509751511506548,0.9311288631778839,0.8984768506055679,0.865321390224588,0.8376309495237928,0.8191823852146706,0.8048318887840842,0.8000182488248575,0.7815695016237492,0.7727215329931365,0.7677819386931114,0.7628020035158677,0.7622508196113859,0.7578465455839277,0.7395853439695771,0.7303787627141427,0.7262489989482007,0.7125194410309073],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"bgcolor\":\"white\",\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"ternary\":{\"bgcolor\":\"white\",\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"xaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"rgb(36,36,36)\",\"automargin\":true,\"zeroline\":false},\"yaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"rgb(36,36,36)\",\"automargin\":true,\"zeroline\":false},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zerolinecolor\":\"rgb(36,36,36)\",\"gridwidth\":2,\"zeroline\":false},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zerolinecolor\":\"rgb(36,36,36)\",\"gridwidth\":2,\"zeroline\":false},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zerolinecolor\":\"rgb(36,36,36)\",\"gridwidth\":2,\"zeroline\":false}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"white\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Number of trees\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Number of trees\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Accuracy\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Log-loss\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"RF Model Performance\"},\"height\":650},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('000d14ce-8ba3-4b2e-9f27-ba68ea6a4c8b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "logs = rf.make_inspector().training_logs()\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Accuracy\", \"Log-loss\"))\n",
        "\n",
        "trees = [log.num_trees for log in logs]\n",
        "accuracy = [log.evaluation.accuracy for log in logs]\n",
        "log_loss = [log.evaluation.loss for log in logs]\n",
        "\n",
        "fig.add_trace(go.Scatter(x=trees, y=accuracy, name=\"Accuracy\"), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=trees, y=log_loss, name=\"Log-loss\"), row=1, col=2)\n",
        "fig.update_xaxes(title=\"Number of trees\")\n",
        "fig.update_layout(title_text=\"RF Model Performance\", height=650)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "KnXavjoGGhCc",
        "outputId": "6d973bab-283a-4221-c543-7c8d1bdf6122"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"07b399f0-5932-423b-8de5-b0261d68f6ae\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"07b399f0-5932-423b-8de5-b0261d68f6ae\")) {                    Plotly.newPlot(                        \"07b399f0-5932-423b-8de5-b0261d68f6ae\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#1F77B4\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[3.314782600849867,51.54961937479675,669.580803444609,1335.546748959925,4759.1937498091975,9342.530470404483,21069.336401881184,43024.86937254015,47049.27415884612,48128.35514280596,65657.78093766747,154214.96538668795,368809.9005498912],\"xaxis\":\"x\",\"y\":[\"age\",\"cryosleep\",\"cabin_num\",\"deck\",\"foodcourt\",\"homeplanet\",\"roomservice\",\"side\",\"destination\",\"shoppingmall\",\"spa\",\"vip\",\"vrdeck\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"bgcolor\":\"white\",\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"ternary\":{\"bgcolor\":\"white\",\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]]},\"xaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"rgb(36,36,36)\",\"automargin\":true,\"zeroline\":false},\"yaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"rgb(36,36,36)\",\"automargin\":true,\"zeroline\":false},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zerolinecolor\":\"rgb(36,36,36)\",\"gridwidth\":2,\"zeroline\":false},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zerolinecolor\":\"rgb(36,36,36)\",\"gridwidth\":2,\"zeroline\":false},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zerolinecolor\":\"rgb(36,36,36)\",\"gridwidth\":2,\"zeroline\":false}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"white\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"RF model gain importances\"},\"barmode\":\"relative\",\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('07b399f0-5932-423b-8de5-b0261d68f6ae');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "inspector = rf.make_inspector()\n",
        "feature_importances = inspector.variable_importances()\n",
        "\n",
        "feature_names = list()\n",
        "importances = list()\n",
        "\n",
        "for i in feature_importances[\"SUM_SCORE\"]:\n",
        "    feature_names.append(str(i[0][0]).split(\" \")[0])\n",
        "    importances.append(i[1])\n",
        "\n",
        "\n",
        "fig = px.bar(x=sorted(importances), y=feature_names, title=\"RF model gain importances\")\n",
        "fig.update_layout(showlegend=False)\n",
        "fig.update_layout(yaxis_title=None)\n",
        "fig.update_layout(xaxis_title=None)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwNqHkel5k87"
      },
      "source": [
        "VIP, vrdeck, and destination are our most important features, with age, food court, and cryosleep being the least important gain importances for the model. Let's take a look the tree visualizations next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "y_CPF4VCKLoh",
        "outputId": "c24750d5-8146-4dca-ca3d-71b4a1c31c53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_3160168376d049568792a980ef958b2b\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'UPLIFT') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'effect: ' + d3.format('r')(value.treatment_effect) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.49453551912568305, 0.505464480874317], \"num_examples\": 6954.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"cryosleep\", \"foodcourt\", \"roomservice\", \"spa\", \"vrdeck\"], \"weights\": [-0.8430414795875549, -0.49383115768432617, 0.25467121601104736, 0.6885967254638672, 0.9181640148162842], \"threshold\": 39.07950973510742}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8309278350515464, 0.16907216494845362], \"num_examples\": 2910.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"shoppingmall\", \"spa\", \"vip\"], \"weights\": [0.22883820533752441, -0.37283068895339966, 0.5760992765426636], \"threshold\": 20.328887939453125}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.6911976911976911, 0.3088023088023088], \"num_examples\": 693.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"cryosleep\", \"foodcourt\", \"roomservice\", \"shoppingmall\", \"spa\", \"vrdeck\"], \"weights\": [-0.21578878164291382, -0.17091089487075806, -0.8761397004127502, 0.2566945552825928, -0.3054051399230957, -0.3084929585456848], \"threshold\": 127.10900115966797}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3333333333333333, 0.6666666666666666], \"num_examples\": 114.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"cryosleep\", \"foodcourt\", \"shoppingmall\", \"spa\", \"vip\", \"vrdeck\"], \"weights\": [0.13406682014465332, -0.4696385860443115, -0.8612334728240967, 0.7905803918838501, -0.6969162225723267, 0.9437189102172852], \"threshold\": -1475.8115234375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4852941176470588, 0.5147058823529411], \"num_examples\": 68.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.10869565217391304, 0.8913043478260869], \"num_examples\": 46.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.7616580310880829, 0.23834196891191708], \"num_examples\": 579.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"foodcourt\", \"roomservice\", \"shoppingmall\", \"spa\", \"vip\", \"vrdeck\"], \"weights\": [-0.8739342093467712, -0.980289876461029, -0.4142230749130249, 0.8601984977722168, -0.01543128490447998, -0.860774576663971, -0.7778106927871704, 0.9460067749023438], \"threshold\": 841.86474609375}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8783068783068783, 0.12169312169312169], \"num_examples\": 189.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"cabin_num\", \"mask\": [\"0\", \"75\", \"78\", \"187\", \"259\", \"24\", \"222\", \"13\", \"8\", \"5\", \"279\", \"233\", \"124\", \"10\", \"48\", \"102\", \"61\", \"317\", \"264\", \"262\", \"242\", \"211\", \"192\", \"112\", \"1023\", \"299\", \"500\", \"284\", \"212\", \"148\", \"603\", \"542\", \"267\", \"1432\", \"1330\"]}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.7051282051282052, 0.2948717948717949], \"num_examples\": 390.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"cabin_num\", \"mask\": [\"<OOD>\", \"19\", \"269\", \"21\", \"175\", \"123\", \"103\", \"259\", \"23\", \"178\", \"150\", \"142\", \"92\", \"156\", \"117\", \"107\", \"94\", \"66\", \"306\", \"226\", \"115\", \"237\", \"140\", \"102\", \"98\", \"61\", \"450\", \"210\", \"211\", \"171\", \"321\", \"244\", \"168\", \"1194\", \"595\", \"439\", \"391\", \"385\", \"1460\", \"1002\", \"88\", \"691\", \"588\", \"547\", \"531\", \"376\", \"169\", \"167\", \"1131\"]}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8746053225078936, 0.12539467749210645], \"num_examples\": 2217.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"roomservice\", \"spa\"], \"weights\": [0.9158241748809814, 0.976978063583374], \"threshold\": 1412.2430419921875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9668989547038328, 0.033101045296167246], \"num_examples\": 574.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"cabin_num\", \"mask\": [\"<OOD>\", \"0\", \"86\", \"269\", \"83\", \"75\", \"230\", \"18\", \"151\", \"144\", \"95\", \"59\", \"186\", \"14\", \"97\", \"55\", \"50\", \"35\", \"20\", \"63\", \"23\", \"13\", \"125\", \"120\", \"1\", \"89\", \"68\", \"43\", \"260\", \"217\", \"152\", \"94\", \"80\", \"53\", \"281\", \"203\", \"189\", \"129\", \"115\", \"11\", \"87\", \"81\", \"47\", \"276\", \"270\", \"182\", \"98\", \"61\", \"58\", \"39\", \"317\", \"315\", \"308\", \"266\", \"264\", \"227\", \"218\", \"210\", \"111\", \"79\", \"291\", \"278\", \"257\", \"250\", \"191\", \"170\", \"15\", \"84\", \"69\", \"533\", \"426\", \"407\", \"307\", \"263\", \"153\", \"1194\", \"972\", \"938\", \"477\", \"335\", \"280\", \"243\", \"235\", \"196\", \"172\", \"17\", \"1289\", \"104\", \"88\", \"558\", \"554\", \"445\", \"248\", \"232\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9918256130790191, 0.008174386920980926], \"num_examples\": 367.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"foodcourt\", \"roomservice\", \"shoppingmall\", \"spa\"], \"weights\": [0.901627779006958, 0.2079942226409912, 0.2776961326599121, -0.0554729700088501, -0.720960259437561, -0.17128455638885498], \"threshold\": -51.771583557128906}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.9227053140096618, 0.07729468599033816], \"num_examples\": 207.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"shoppingmall\", \"spa\", \"vip\", \"vrdeck\"], \"weights\": [0.6221423149108887, 0.9203191995620728, 0.27076268196105957, 0.7623451948165894, 0.4345276355743408, 0.5702604055404663], \"threshold\": 3212.7900390625}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8423615337796714, 0.15763846622032868], \"num_examples\": 1643.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"foodcourt\", \"roomservice\", \"shoppingmall\", \"spa\", \"vrdeck\"], \"weights\": [-0.7918881773948669, 0.8676241636276245, 0.7821977138519287, 0.8475441932678223, 0.516585111618042, 0.496366024017334, -0.2620745897293091], \"threshold\": -395.5470886230469}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.8317089018843404, 0.1682910981156595], \"num_examples\": 1539.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"cabin_num\", \"mask\": [\"<OOD>\", \"86\", \"269\", \"118\", \"109\", \"176\", \"151\", \"144\", \"59\", \"27\", \"21\", \"20\", \"259\", \"23\", \"150\", \"137\", \"133\", \"120\", \"68\", \"525\", \"32\", \"238\", \"217\", \"194\", \"16\", \"1476\", \"117\", \"94\", \"80\", \"67\", \"54\", \"53\", \"41\", \"25\", \"226\", \"981\", \"74\", \"49\", \"48\", \"258\", \"206\", \"179\", \"1411\", \"140\", \"116\", \"51\", \"450\", \"339\", \"308\", \"268\", \"264\", \"249\", \"215\", \"195\", \"193\", \"190\", \"184\", \"173\", \"149\", \"136\", \"111\", \"1046\", \"323\", \"285\", \"257\", \"202\", \"192\", \"171\", \"157\", \"145\", \"119\", \"994\", \"70\", \"69\", \"601\", \"52\", \"505\", \"407\", \"4\", \"321\", \"319\", \"289\", \"244\", \"221\", \"165\", \"159\", \"155\", \"1194\", \"856\", \"810\", \"657\", \"571\", \"477\", \"461\", \"420\", \"391\", \"343\", \"335\", \"324\", \"293\", \"243\", \"224\", \"196\", \"1416\", \"1289\", \"128\", \"104\", \"958\", \"893\", \"882\", \"813\", \"762\", \"655\", \"642\", \"603\", \"575\", \"554\", \"548\", \"531\", \"510\", \"508\", \"445\", \"390\", \"386\", \"338\", \"336\", \"314\", \"312\", \"271\", \"1704\", \"169\", \"1453\", \"1278\", \"1118\", \"108\"]}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [1.0, 0.0], \"num_examples\": 104.0}}]}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.25247279920870425, 0.7475272007912958], \"num_examples\": 4044.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"homeplanet\", \"mask\": [\"Europa\", \"Mars\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.11556982343499198, 0.884430176565008], \"num_examples\": 1869.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"cryosleep\", \"foodcourt\", \"roomservice\", \"shoppingmall\"], \"weights\": [-0.3469608426094055, 0.8881820440292358, 0.4785062074661255, 0.41182589530944824], \"threshold\": -0.17348042130470276}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.24882629107981222, 0.7511737089201878], \"num_examples\": 639.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"foodcourt\", \"roomservice\", \"spa\", \"vrdeck\"], \"weights\": [0.13052964210510254, 0.32144904136657715, -0.18678802251815796, 0.9507178068161011, 0.8219835758209229, -0.537371039390564], \"threshold\": 2.3495335578918457}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.4759825327510917, 0.5240174672489083], \"num_examples\": 229.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"roomservice\", \"shoppingmall\", \"spa\", \"vrdeck\"], \"weights\": [-0.3479929566383362, 0.8234132528305054, -0.8089020252227783, 0.41179561614990234, 0.4272289276123047], \"threshold\": -9.221813201904297}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.12195121951219512, 0.8780487804878049], \"num_examples\": 410.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"foodcourt\", \"shoppingmall\", \"vip\", \"vrdeck\"], \"weights\": [-0.11172324419021606, -0.9405707120895386, -0.09955602884292603, -0.2644529342651367, 0.06928503513336182, 0.8907502889633179], \"threshold\": 11.979766845703125}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.046341463414634146, 0.9536585365853658], \"num_examples\": 1230.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"deck\", \"mask\": [\"F\", \"C\", \"B\", \"D\", \"A\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.008992805755395683, 0.9910071942446043], \"num_examples\": 1112.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"foodcourt\", \"vip\", \"vrdeck\"], \"weights\": [0.22957265377044678, 0.0666651725769043, 0.6436817646026611, -0.19954913854599], \"threshold\": 8.127311706542969}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3983050847457627, 0.6016949152542372], \"num_examples\": 118.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"side\", \"mask\": [\"S\"]}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3701149425287356, 0.6298850574712643], \"num_examples\": 2175.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"roomservice\", \"spa\", \"vip\", \"vrdeck\"], \"weights\": [0.23775756359100342, 0.8460270166397095, -0.6558887958526611, -0.8706392049789429, 0.08724570274353027, -0.5466172695159912], \"threshold\": -42.43785858154297}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3442879499217527, 0.6557120500782473], \"num_examples\": 1917.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"foodcourt\", \"shoppingmall\", \"vrdeck\"], \"weights\": [0.4031296968460083, 0.6493879556655884, 0.47034943103790283], \"threshold\": 636.6019897460938}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0625, 0.9375], \"num_examples\": 80.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"roomservice\", \"vip\", \"vrdeck\"], \"weights\": [-0.32672005891799927, 0.8933883905410767, -0.981532633304596], \"threshold\": -1.6336002349853516}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.356559608056614, 0.643440391943386], \"num_examples\": 1837.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"foodcourt\", \"shoppingmall\", \"spa\", \"vip\"], \"weights\": [-0.7966877222061157, 0.7199374437332153, -0.05866044759750366, -0.15628337860107422, -0.01830047369003296], \"threshold\": -38.59297561645508}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.562015503875969, 0.437984496124031], \"num_examples\": 258.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"foodcourt\", \"shoppingmall\", \"vip\", \"vrdeck\"], \"weights\": [0.8095760345458984, 0.16174769401550293, -0.24083596467971802, -0.31397920846939087, -0.8905100226402283, 0.46102702617645264], \"threshold\": -157.6424560546875}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.6646341463414634, 0.3353658536585366], \"num_examples\": 164.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"foodcourt\", \"spa\"], \"weights\": [-0.14729535579681396, 0.6788419485092163, -0.724722683429718, -0.21089816093444824], \"threshold\": -531.6647338867188}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.3829787234042553, 0.6170212765957447], \"num_examples\": 94.0}, \"condition\": {\"type\": \"NUMERICAL_SPARSE_OBLIQUE\", \"attributes\": [\"age\", \"cryosleep\", \"foodcourt\", \"roomservice\", \"shoppingmall\", \"spa\", \"vip\", \"vrdeck\"], \"weights\": [-0.4166841506958008, -0.664031982421875, 0.9513577222824097, 0.29543840885162354, 0.9322988986968994, -0.7541465759277344, 0.954272985458374, -0.2675776481628418], \"threshold\": 972.2971801757812}}]}]}]}]}, \"#tree_plot_3160168376d049568792a980ef958b2b\")\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(rf, tree_idx=0, max_depth=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUGXDod2MRHJ"
      },
      "source": [
        "Now that we've seen how the model performs on the training dataset, we can prepare data from the test set, predict the transported label, and create a csv file for submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnRXdisCGmPA",
        "outputId": "87b5a153-b3d1-4b9d-fb8e-ae40be080097"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 14 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7c03ac16da20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 65ms/step\n"
          ]
        }
      ],
      "source": [
        "test_pd = pd.read_csv(test_csv).rename(columns=str.lower)\n",
        "passenger_ids = test_pd[\"passengerid\"]\n",
        "\n",
        "test_pd[[\"vip\", \"cryosleep\"]] = test_pd[[\"vip\", \"cryosleep\"]].fillna(value=0)\n",
        "\n",
        "test_pd[[\"deck\", \"cabin_num\", \"side\"]] = test_pd[\"cabin\"].str.split(\"/\", expand=True)\n",
        "test_pd = test_pd.drop(\"cabin\", axis=1)\n",
        "\n",
        "test_pd[\"vip\"] = test_pd[\"vip\"].astype(int)\n",
        "test_pd[\"cryosleep\"] = test_pd[\"cryosleep\"].astype(int)\n",
        "\n",
        "test_pd_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_pd)\n",
        "\n",
        "predictions = rf.predict(test_pd_ds)\n",
        "boolean_predictions = (predictions > 0.5).astype(bool)\n",
        "\n",
        "\n",
        "predictions_df = pd.DataFrame(\n",
        "    {\"PassengerId\": passenger_ids, \"Transported\": boolean_predictions.squeeze()}\n",
        ")\n",
        "\n",
        "predictions_df.set_index(\"PassengerId\", inplace=True)\n",
        "predictions_df.to_csv(\"tensorflow_rf_submissions.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM4_oSw-4gpX"
      },
      "source": [
        "This model reached a test accuracy of 0.79284, which vastly outperforms our other supervised learning models as well as the unsupervised learning models we tried.  \n",
        "\n",
        "In the next cell, we'll save the model and export it as a zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mBGGgaUlCQEY",
        "outputId": "e4ef4de3-be64-4f94-e86c-45fb5c48441c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_6ad6cabe-c6bf-4f17-8837-ce90ad5ca9d7\", \"rf_model_10_1.zip\", 2140981)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_save_path = \"/content/rf_model_10_1.tf\"\n",
        "rf.save(model_save_path)\n",
        "\n",
        "import os, zipfile\n",
        "from google.colab import files as colab_files\n",
        "\n",
        "\n",
        "# 2. Create a zip file of the saved model directory\n",
        "zip_path = \"/content/rf_model_10_1.zip\"\n",
        "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(model_save_path):\n",
        "        for file in files:\n",
        "            zipf.write(\n",
        "                os.path.join(root, file),\n",
        "                os.path.relpath(\n",
        "                    os.path.join(root, file), os.path.join(model_save_path, \"..\")\n",
        "                ),\n",
        "            )\n",
        "\n",
        "colab_files.download(zip_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY4odTHjNugF"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this Kaggle competition, we tried a few different approaches based off the starting assumption that ensemble models would give us a leg up on predicting labels for the blind test set. After our initial analysis and data cleaning classifiers were trained using TPOT, LGBM, XGB, CatBoost, and AdaBoost packages, before moving to stacking and voting classifiers.\n",
        "\n",
        "In none of these cases did our models perform to the level needed. From there we moved to KNN and Label Spreading classifiers before having more success with the the Tensorflow Random Forest model.\n",
        "\n",
        "This model reached our target accuracy, and is the final model used in this competition.\n",
        "\n",
        "## Recommendations for further research\n",
        "\n",
        "In future iterations of this project, a deeper dive into the use of other tensorflow models or more manually calibrated hyperparameters might give us a little more performance on the accuracy front. Additionally, we could explore how to chain supervised and unsupervised classifiers in order strengthen weaker classifiers similar to how we did with a stacking classifier in this project.\n",
        "\n",
        "Lastly, a different approach could be to restrict models to only model types that can be feasibly trained without GPU resources, but require the same level of accuracy for passing submissions."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
